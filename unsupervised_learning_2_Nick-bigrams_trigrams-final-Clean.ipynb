{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lasting-disaster",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (5.0.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "challenging-closure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /opt/conda/lib/python3.7/site-packages (2.1.2)\n",
      "Requirement already satisfied: future in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (0.18.2)\n",
      "Requirement already satisfied: numexpr in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (2.7.3)\n",
      "Requirement already satisfied: funcy in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (1.15)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (1.4.1)\n",
      "Requirement already satisfied: wheel>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (0.36.2)\n",
      "Requirement already satisfied: pytest in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (7.1.3)\n",
      "Requirement already satisfied: pandas>=0.17.0 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (1.2.3)\n",
      "Requirement already satisfied: numpy>=1.9.2 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (1.20.1)\n",
      "Requirement already satisfied: joblib>=0.8.4 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (1.0.1)\n",
      "Requirement already satisfied: jinja2>=2.7.2 in /opt/conda/lib/python3.7/site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.7/site-packages (from jinja2>=2.7.2->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas>=0.17.0->pyLDAvis) (2021.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis) (1.15.0)\n",
      "Requirement already satisfied: py>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.11.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (3.7.2)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (20.9)\n",
      "Requirement already satisfied: iniconfig in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.1.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (20.3.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /opt/conda/lib/python3.7/site-packages (from pytest->pyLDAvis) (1.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (3.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.12->pytest->pyLDAvis) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->pytest->pyLDAvis) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "! pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coastal-storm",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/conda/lib/python3.7/site-packages (2.3.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in /opt/conda/lib/python3.7/site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.8.2)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from spacy) (49.6.0.post20210108)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (0.7.4)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.7/site-packages (from spacy) (4.58.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20 in /opt/conda/lib/python3.7/site-packages (from catalogue<1.1.0,>=0.0.7->spacy) (3.7.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy) (3.4.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.3)\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "white-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Slow version of gensim.models.doc2vec is being used\n",
      "Slow version of Fasttext is being used\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.multivariate.pca import PCA\n",
    "import numpy as np\n",
    "import json\n",
    "import glob\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import TfidfModel\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "horizontal-registration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label\n",
       "0       There is manuscript evidence that Austen conti...      1\n",
       "1       In a remarkable comparative analysis , Mandaea...      1\n",
       "2       Before Persephone was released to Hermes , who...      1\n",
       "3       Cogeneration plants are commonly found in dist...      1\n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1\n",
       "...                                                   ...    ...\n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0\n",
       "416764  However , it is becoming replaced as a method ...      0\n",
       "416765  There are hand gestures in both Hindu and Budd...      0\n",
       "416766  If it is necessary to use colors , try to choo...      0\n",
       "416767                               Calgary Stampeders ,      0\n",
       "\n",
       "[416768 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('WikiLarge_Train.csv')\n",
    "test_df = pd.read_csv('WikiLarge_Test.csv')\n",
    "train_df#['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "governing-integral",
   "metadata": {},
   "outputs": [],
   "source": [
    "# much of the following work will be heavily influenced by the following instructional video: https://youtu.be/UEn3xHNBXJU?list=LL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-buffalo",
   "metadata": {},
   "source": [
    "# Using LDA to train supervised learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "entire-yield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def lemmatize_sentence(sentences, p_o_s=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\\n    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\\n    sentences_out = []\\n    for sentence in tqdm(sentences):\\n        doc = nlp(sentence)\\n        new_sent = []\\n        for token in doc:\\n            if token.pos_ in p_o_s:\\n                new_sent.append(token.lemma_)\\n        final = \" \".join(new_sent)\\n        sentences_out.append(final)\\n    return(sentences_out)\\n\\n\\nlemmatized_sentences = lemmatize_sentence(train_df[\\'original_text\\'])\\nprint (lemmatized_sentences[0][0:50])\\n\\npd.DataFrame(lemmatized_sentences).to_csv(\\'lemmatized_sentences.csv\\', index = False)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved to csv\n",
    "def lemmatize_sentence(sentences, p_o_s=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    sentences_out = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        new_sent = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in p_o_s:\n",
    "                new_sent.append(token.lemma_)\n",
    "        final = \" \".join(new_sent)\n",
    "        sentences_out.append(final)\n",
    "    return(sentences_out)\n",
    "\n",
    "\n",
    "lemmatized_sentences = lemmatize_sentence(train_df['original_text'])\n",
    "print (lemmatized_sentences[0][0:50])\n",
    "\n",
    "pd.DataFrame(lemmatized_sentences).to_csv('lemmatized_sentences.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "similar-frederick",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manuscript evidence continue work piece as lat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>remarkable comparative analysis mandaean schol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>release send retrieve trick eat pomegranate se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cogeneration plant commonly find district heat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>second most populous city zürich most populous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>3d version sell live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>however become replace method execute criminal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>hand gesture iconography</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>necessary use color try choose color will conf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "0       manuscript evidence continue work piece as lat...\n",
       "1       remarkable comparative analysis mandaean schol...\n",
       "2       release send retrieve trick eat pomegranate se...\n",
       "3       cogeneration plant commonly find district heat...\n",
       "4       second most populous city zürich most populous...\n",
       "...                                                   ...\n",
       "416763                               3d version sell live\n",
       "416764  however become replace method execute criminal...\n",
       "416765                           hand gesture iconography\n",
       "416766  necessary use color try choose color will conf...\n",
       "416767                                                NaN\n",
       "\n",
       "[416768 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sentences = pd.read_csv('lemmatized_sentences.csv')\n",
    "lemmatized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "charming-philosophy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         manuscript evidence continue work piece as lat...\n",
       "1         remarkable comparative analysis mandaean schol...\n",
       "2         release send retrieve trick eat pomegranate se...\n",
       "3         cogeneration plant commonly find district heat...\n",
       "4         second most populous city zürich most populous...\n",
       "                                ...                        \n",
       "416763                                 3d version sell live\n",
       "416764    however become replace method execute criminal...\n",
       "416765                             hand gesture iconography\n",
       "416766    necessary use color try choose color will conf...\n",
       "416767                                                  NaN\n",
       "Name: 0, Length: 416768, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sentences['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adjustable-scenario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416690</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416694</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416730</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416745</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15949 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "31      NaN\n",
       "90      NaN\n",
       "104     NaN\n",
       "140     NaN\n",
       "145     NaN\n",
       "...     ...\n",
       "416690  NaN\n",
       "416694  NaN\n",
       "416730  NaN\n",
       "416745  NaN\n",
       "416767  NaN\n",
       "\n",
       "[15949 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df = lemmatized_sentences[lemmatized_sentences.isna().any(axis=1)]\n",
    "nan_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "increasing-discretion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [original_text, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_df2 = train_df[train_df.isna().any(axis=1)]\n",
    "nan_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "direct-check",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manuscript evidence continue work piece as late period niece nephew make further addition \n"
     ]
    }
   ],
   "source": [
    "print(lemmatized_sentences['0'][0][0:90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "wrong-dodge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lemmatized_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "running-honduras",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40    bear american professional wrestler actor well...\n",
       "41                 situate northern border coastline km\n",
       "42    shade red orange may sometimes appear replace ...\n",
       "43    also know name take newspaper mean clarion tak...\n",
       "44    guitar traditionally construct various wood st...\n",
       "45    player take role engineer name battle polymorp...\n",
       "46             rez bear also know mexican racing driver\n",
       "47         order book bind book click order book button\n",
       "48    conflict parent religion mean most baptise bir...\n",
       "49                           ndash german mathematician\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatized_sentences['0'][40:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "molecular-exception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    On July 29 , 2008 the Palace announced that Ki...\n",
       "31                               F. W. D. Brie , 1906 .\n",
       "32    Simon Boccanegra is an opera with a prologue a...\n",
       "33    On June 6 , 2000 , ten days before the movie w...\n",
       "34    The Bushehr Nuclear Power Plant -LRB- -RRB- is...\n",
       "Name: original_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['original_text'][30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "individual-details",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_sentences = lemmatized_sentences.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "durable-contamination",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [00:08<00:00, 47273.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manuscript', 'evidence', 'continue', 'work', 'piece', 'as', 'late', 'period', 'niece', 'nephew', 'make', 'further', 'addition', 'as', 'late']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def gen_words(sentences):\n",
    "    final = []\n",
    "    for sentence in tqdm(sentences['0']):\n",
    "        new = gensim.utils.simple_preprocess(sentence, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "clean_words = gen_words(lemmatized_sentences)\n",
    "\n",
    "print (clean_words[0][0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-creativity",
   "metadata": {},
   "source": [
    "# Bigrams and trigrams train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fiscal-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['manuscript', 'evidence', 'continue', 'work', 'piece', 'as', 'late', 'period', 'niece', 'nephew', 'make', 'further', 'addition', 'as', 'late']\n"
     ]
    }
   ],
   "source": [
    "bi_phrases = gensim.models.Phrases(clean_words, min_count=5, threshold=100)\n",
    "tri_phrases = gensim.models.Phrases(bi_phrases[clean_words], threshold=100)\n",
    "bigram = gensim.models.phrases.Phraser(bi_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(tri_phrases)\n",
    "\n",
    "def make_bigrams(sentences):\n",
    "    return([bigram[doc] for doc in sentences])\n",
    "def make_trigrams(sentences):\n",
    "    return ([trigram[bigram[doc]] for doc in sentences])\n",
    "\n",
    "data_bigrams = make_bigrams(clean_words)\n",
    "data_bigrams_trigrams = make_trigrams(data_bigrams)\n",
    "print (data_bigrams_trigrams[0][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fluid-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 416768/416768 [00:09<00:00, 45426.28it/s]\n"
     ]
    }
   ],
   "source": [
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "sentences = data_bigrams_trigrams\n",
    "corpus = [id2word.doc2bow(sentence) for sentence in sentences]\n",
    "# print (corpus[0][0:20])\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "low_value = 0.03\n",
    "words  = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in tqdm(range(0, len(corpus))):\n",
    "    bow = corpus[i]\n",
    "    low_val_words = []\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_val_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_val_words+words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "\n",
    "    new_bow = [b for b in bow if b[0] not in low_val_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus[i] = new_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "endless-grain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# bi tri model saved\\nBi_tri_lda_model = gensim.models.ldamodel.LdaModel(corpus=tqdm(corpus),\\n                                           id2word=id2word,\\n                                           num_topics=20,\\n                                           random_state=40,\\n                                           update_every=1,\\n                                           chunksize=80,\\n                                           passes=8,\\n                                           alpha=\"auto\")\\n                                           \\nBi_tri_lda_model.save(\"Bi_tri_lda_model.model\")'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bi tri model saved\n",
    "Bi_tri_lda_model = gensim.models.ldamodel.LdaModel(corpus=tqdm(corpus),\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20,\n",
    "                                           random_state=40,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=80,\n",
    "                                           passes=8,\n",
    "                                           alpha=\"auto\")\n",
    "                                           \n",
    "Bi_tri_lda_model.save(\"Bi_tri_lda_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "experienced-somalia",
   "metadata": {},
   "outputs": [],
   "source": [
    "Bi_tri_lda_model_saved_model = gensim.models.ldamodel.LdaModel.load(\"Bi_tri_lda_model.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "heated-bridal",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el5441396629833950241290649888\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el5441396629833950241290649888_data = {\"mdsDat\": {\"x\": [-0.40310795755268974, -0.48873925980618493, -0.058945493154342804, -0.1422256081193992, 0.09389933034162463, -0.14712889726483408, -0.3811315468343309, -0.31925484792806885, 0.05627245999880775, 0.3278123686533018, 0.16786125526600462, 0.2570142600637742, -0.30925755979295416, 0.10763128923676471, -0.23988944346373758, -0.05938088681390566, 0.27764203348605326, 0.4582446530214715, 0.4391539454949411, 0.3635299051677041], \"y\": [-0.19835305707530404, 0.0553390869311458, -0.19284433820530356, -0.4339513781813857, 0.4639281542147686, 0.15874230801538847, 0.24884120944818344, -0.34393527915487826, -0.47164384100231704, -0.36699089188106226, -0.2947605487267388, 0.3732363092242356, -0.019618247747366934, 0.10889437527938717, 0.40508125379491233, 0.39723175985704673, -0.11301027047710357, -0.1040930584709434, 0.08920436194858458, 0.23870209220875044], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [9.628153300379907, 6.523407878100882, 5.773782112466423, 5.552992110808579, 5.494104724447936, 5.164801675150408, 5.106026148169541, 5.0954994534397375, 5.018719596902907, 4.939608148916877, 4.899520173249286, 4.420342436365473, 4.345974494651169, 4.308096185821299, 4.1876956181535006, 4.153211038347354, 3.899681158330856, 3.8820718869299795, 3.8426981558951128, 3.763613703472774]}, \"tinfo\": {\"Term\": [\"nan\", \"bear\", \"also\", \"use\", \"make\", \"first\", \"other\", \"find\", \"name\", \"play\", \"city\", \"region\", \"call\", \"time\", \"know\", \"department\", \"can\", \"people\", \"become\", \"year\", \"many\", \"player\", \"football\", \"when\", \"most\", \"more\", \"commune\", \"part\", \"include\", \"state\", \"lrb\", \"area\", \"only\", \"rrb\", \"come\", \"season\", \"number\", \"die\", \"band\", \"album\", \"word\", \"history\", \"language\", \"move\", \"begin\", \"song\", \"record\", \"english\", \"island\", \"japanese\", \"help\", \"leave\", \"set\", \"child\", \"found\", \"line\", \"great\", \"law\", \"design\", \"stop\", \"good\", \"lead\", \"hold\", \"point\", \"single\", \"cause\", \"story\", \"county\", \"open\", \"produce\", \"specie\", \"support\", \"woman\", \"keep\", \"how\", \"modern\", \"wife\", \"central\", \"cell\", \"again\", \"storm\", \"idea\", \"car\", \"church\", \"ancient\", \"attack\", \"light\", \"train\", \"night\", \"hurricane\", \"use\", \"first\", \"other\", \"work\", \"would\", \"day\", \"event\", \"much\", \"role\", \"present\", \"meet\", \"position\", \"month\", \"kind\", \"teach\", \"space\", \"site\", \"information\", \"free\", \"week\", \"hard\", \"problem\", \"announce\", \"fly\", \"successful\", \"element\", \"copy\", \"relative\", \"operation\", \"medical\", \"become\", \"when\", \"part\", \"start\", \"old\", \"win\", \"world\", \"second\", \"create\", \"own\", \"death\", \"match\", \"appear\", \"east\", \"title\", \"website\", \"describe\", \"speak\", \"rock\", \"brother\", \"head\", \"have\", \"age\", \"young\", \"final\", \"soon\", \"job\", \"engine\", \"musician\", \"election\", \"also\", \"city\", \"player\", \"football\", \"take\", \"member\", \"book\", \"mean\", \"capital\", \"same\", \"main\", \"last\", \"order\", \"body\", \"singer\", \"center\", \"represent\", \"one\", \"career\", \"style\", \"add\", \"party\", \"professional\", \"introduce\", \"stadium\", \"greek\", \"tribe\", \"tropical_storm\", \"tropical\", \"newspaper\", \"make\", \"north\", \"small\", \"go\", \"often\", \"big\", \"th_century\", \"son\", \"grow\", \"land\", \"official\", \"river\", \"allow\", \"original\", \"control\", \"together\", \"separate\", \"few\", \"wall\", \"class\", \"range\", \"increase\", \"size\", \"material\", \"store\", \"ball\", \"police\", \"fish\", \"occur\", \"charge\", \"find\", \"people\", \"large\", \"form\", \"see\", \"government\", \"popular\", \"get\", \"there\", \"human\", \"program\", \"art\", \"hand\", \"metal\", \"turn\", \"like\", \"territory\", \"battle\", \"capture\", \"standard\", \"length\", \"adult\", \"least\", \"expensive\", \"prove\", \"cut\", \"product\", \"catch\", \"occupy\", \"earthquake\", \"year\", \"most\", \"later\", \"new\", \"place\", \"famous\", \"several\", \"long\", \"example\", \"important\", \"color\", \"should\", \"mother\", \"happen\", \"race\", \"never\", \"defeat\", \"house\", \"structure\", \"believe\", \"consider\", \"complete\", \"complex\", \"driver\", \"king\", \"instead\", \"non\", \"middle\", \"community\", \"sister\", \"bear\", \"know\", \"well\", \"such\", \"former\", \"where\", \"as\", \"run\", \"person\", \"father\", \"lose\", \"top\", \"currently\", \"brazilian\", \"student\", \"right\", \"level\", \"hit\", \"daughter\", \"division\", \"director\", \"process\", \"share\", \"activity\", \"canadian\", \"fall\", \"ring\", \"heart\", \"council\", \"manager\", \"call\", \"team\", \"game\", \"different\", \"may\", \"national\", \"sometimes\", \"follow\", \"water\", \"close\", \"home\", \"video\", \"contain\", \"building\", \"friend\", \"spanish\", \"develop\", \"surface\", \"sport\", \"model\", \"sound\", \"user\", \"text\", \"full\", \"strong\", \"sea\", \"replace\", \"picture\", \"temperature\", \"coach\", \"many\", \"give\", \"live\", \"early\", \"will\", \"film\", \"school\", \"force\", \"actor\", \"could\", \"rule\", \"next\", \"short\", \"return\", \"less\", \"accord\", \"period\", \"reach\", \"eat\", \"field\", \"link\", \"send\", \"claim\", \"energy\", \"officially\", \"independent\", \"symbol\", \"natural\", \"quickly\", \"generally\", \"show\", \"release\", \"then\", \"movie\", \"population\", \"study\", \"company\", \"page\", \"pay\", \"sell\", \"put\", \"total\", \"university\", \"service\", \"computer\", \"letter\", \"degree\", \"college\", \"finish\", \"flag\", \"connect\", \"organization\", \"nation\", \"project\", \"culture\", \"code\", \"graduate\", \"ground\", \"port\", \"scene\", \"play\", \"include\", \"base\", \"usually\", \"french\", \"character\", \"think\", \"feature\", \"kill\", \"club\", \"italian\", \"leader\", \"marry\", \"originally\", \"receive\", \"act\", \"special\", \"theory\", \"president\", \"opera\", \"religious\", \"certain\", \"political\", \"winner\", \"bring\", \"agree\", \"sing\", \"regular\", \"orchestra\", \"european\", \"can\", \"write\", \"locate\", \"south\", \"west\", \"km\", \"way\", \"common\", \"star\", \"southwest\", \"village\", \"border\", \"current\", \"animal\", \"direct\", \"article\", \"mile\", \"half\", \"actress\", \"northern\", \"coast\", \"christian\", \"southern\", \"mountain\", \"damage\", \"railway\", \"guitar\", \"eventually\", \"string\", \"collection\", \"more\", \"music\", \"say\", \"change\", \"british\", \"just\", \"continue\", \"try\", \"result\", \"late\", \"writer\", \"image\", \"discover\", \"mainly\", \"roman\", \"label\", \"piece\", \"development\", \"rather\", \"green\", \"research\", \"industry\", \"blood\", \"compete\", \"influence\", \"moon\", \"loss\", \"room\", \"dead\", \"retire\", \"nan\", \"region\", \"department\", \"commune\", \"very\", \"group\", \"end\", \"build\", \"power\", \"back\", \"join\", \"station\", \"cover\", \"western\", \"decide\", \"branch\", \"lake\", \"wide\", \"belong\", \"husband\", \"leg\", \"beginning\", \"arda_che_partement_southern\", \"apart\", \"tradition\", \"partement\", \"rare\", \"shore\", \"parallel\", \"airline\", \"american\", \"country\", \"series\", \"life\", \"system\", \"television\", \"northwest\", \"reference\", \"term\", \"plant\", \"need\", \"want\", \"episode\", \"mostly\", \"military\", \"composer\", \"money\", \"network\", \"provide\", \"available\", \"commonly\", \"real\", \"involve\", \"tv\", \"radio\", \"scale\", \"meaning\", \"nearby\", \"beat\", \"past\", \"time\", \"family\", \"about\", \"now\", \"german\", \"however\", \"so\", \"version\", \"publish\", \"side\", \"award\", \"public\", \"bird\", \"white\", \"wind\", \"black\", \"genus\", \"ago\", \"double\", \"voice\", \"case\", \"powerful\", \"instruction\", \"rise\", \"stone\", \"machine\", \"peak\", \"contract\", \"ndash\", \"celebrate\", \"state\", \"high\", \"type\", \"province\", \"even\", \"district\", \"list\", \"unit\", \"low\", \"serve\", \"municipality\", \"fight\", \"politician\", \"author\", \"league\", \"flow\", \"talk\", \"choose\", \"enter\", \"planet\", \"report\", \"municipality_locate_belgian\", \"table\", \"method\", \"effect\", \"value\", \"distance\", \"probably\", \"typically\", \"asteroid\", \"name\", \"town\", \"th\", \"still\", \"major\", \"man\", \"war\", \"third\", \"look\", \"similar\", \"thing\", \"air\", \"refer\", \"must\", \"ship\", \"around\", \"visit\", \"emperor\", \"eastern\", \"route\", \"possible\", \"blue\", \"ever\", \"native\", \"carry\", \"measure\", \"merge\", \"wave\", \"dry\", \"cloud\"], \"Freq\": [24691.0, 21237.0, 21725.0, 21359.0, 19497.0, 19910.0, 19357.0, 18478.0, 15526.0, 15147.0, 15652.0, 14184.0, 14749.0, 12368.0, 13430.0, 12148.0, 11878.0, 12268.0, 12410.0, 11509.0, 11333.0, 11597.0, 11470.0, 11369.0, 10853.0, 9486.0, 9423.0, 10297.0, 8715.0, 8073.0, 9473.168855335936, 7791.725324929398, 7426.5865018291415, 6329.61828222229, 5861.667648928495, 5641.818708411852, 5641.18238284745, 5500.404346632435, 5433.685765403278, 5331.494346935291, 4663.661415188487, 4476.118075943106, 4380.089969141315, 4365.348598230925, 4144.766701127176, 3777.3179853884503, 3613.6121830576844, 3600.3485472019447, 3566.153244042536, 3377.728403712381, 3313.32819603592, 3074.939463024934, 3025.7452775595248, 2703.1801298824435, 2608.411824339417, 2592.639893851784, 2237.6748268573438, 2062.3616084203504, 2050.48318855497, 1918.6955639137473, 4608.389728741511, 3619.698098725116, 3495.4183676602706, 3287.415671860283, 2843.214971418984, 2765.21374283817, 2699.130476250146, 2658.0948671199444, 2643.4859827130044, 2582.326961360659, 2427.212714062794, 2338.1101681198606, 2198.646418913512, 2154.8110594599557, 2106.756485497709, 2027.0251543475279, 2021.4827665875675, 1984.8594762081484, 1904.2542134158923, 1871.2485368630812, 1863.298353377556, 1833.8610133740651, 1692.3652294470528, 1578.7593397169726, 1543.8980167187358, 1542.8414283138525, 1417.466975544739, 1372.627526269699, 1365.8990013617386, 1362.7846077872916, 21357.905767083394, 19909.32797990839, 19356.488804551653, 8859.631933215047, 4021.6847081231704, 3965.712141195562, 3033.23086946967, 2898.4640143592987, 2108.4758666467137, 1775.1252681752717, 1722.2941901934162, 1704.7866772304267, 1563.3791423131697, 1259.0237439746534, 1214.1390887889352, 1212.320064356698, 1127.9513439765078, 1086.912793487131, 1083.4170702231959, 1081.410564369132, 1022.5683681160757, 1001.9335448269858, 942.7888199828523, 838.3474123481894, 827.5748978358654, 808.5470361459401, 778.75644627356, 757.7379526189652, 750.9366845329644, 706.2387401919175, 12409.084106524831, 11368.111222033958, 10296.494319770902, 7258.608280021618, 6122.759059579504, 5940.199306912638, 5199.408072658339, 4817.119415355878, 3650.3377370485923, 3395.9092666185315, 3127.122230572893, 2811.6375438715554, 2623.3777643722447, 2610.1213778581355, 2584.208311210302, 2469.4119704199497, 2201.719257707574, 2063.0050671716026, 2043.2942036332147, 1985.1440287098922, 1926.801016910425, 1862.525121451131, 1813.9493493060957, 1398.3102879735563, 1192.1246088720372, 1179.8017247760354, 1153.6317152190577, 1152.8325760816765, 1055.6022517764857, 1055.314849237789, 21724.554557213458, 15651.706306962922, 11596.214615485123, 11469.796274675591, 7279.386983235601, 5559.560221882952, 5217.073924897639, 4965.1482343382795, 4531.475134561118, 4461.9822962673825, 3930.0925695776277, 3176.1671033599246, 2196.3186406890277, 2177.19912050082, 2092.6542520433454, 1677.9443433382216, 1568.4032411163012, 1450.9629723715225, 1420.0158200282283, 1239.2393818030707, 1214.2578863840047, 1191.5334842360157, 1181.5985929231854, 985.3277541975854, 980.8111479270847, 814.1987728877978, 776.8226956296753, 759.995611411416, 751.7285728548695, 748.5747135937565, 19496.338959868062, 8758.165063510798, 5842.187557937463, 5738.883832969461, 4808.932488900768, 3328.1000000135414, 3197.8630494536833, 3114.1388031639444, 2447.469851312484, 2382.1695382278417, 2299.7112635534813, 2083.402442764183, 2046.2441148405605, 2043.1564565295914, 2018.66184270997, 1907.927582612132, 1595.0087084015022, 1341.1577564677154, 1270.0886769401338, 1071.1973398538003, 1048.235250640773, 1027.3909032299493, 998.4464329580593, 950.7213847496148, 863.0630175856463, 852.23636160652, 846.8855877518231, 839.6732855597144, 835.8950158137852, 835.0414534423799, 18477.263164859614, 12267.28383396713, 8454.431011919658, 6144.622650497009, 4790.285844729184, 4168.481502097035, 2854.9907134953946, 2827.4279384313763, 2115.3441066806554, 2097.5072292962727, 1774.3947025603118, 1705.131635212666, 1549.830742786828, 1446.9020396207086, 1324.2861656760736, 1195.2779478325265, 1042.2883547971132, 1012.6923831469375, 927.9104160887982, 919.9514695514904, 794.9296417701854, 721.7319069842717, 710.3288061145802, 695.420424175081, 694.2676706742283, 686.9346428473326, 673.1772426191957, 669.2479586951491, 666.7308591408218, 663.4892339763583, 11508.78892340122, 10852.360817544652, 5789.165278542238, 5716.337630750153, 5308.661336973962, 4160.652865004633, 4080.305467707212, 4068.1376947683048, 3012.0426825047803, 2839.121902469434, 2298.677581686874, 2108.908362754789, 1806.5323638938987, 1777.8574024472857, 1686.4477256992254, 1584.3234123838938, 1520.4032294097417, 1472.130920492154, 1306.5582446887433, 1209.7800967945918, 1204.732882491425, 1173.700858772213, 1169.8860357703745, 1149.5234931265409, 1127.3310649769053, 1089.4794738977325, 1038.3002801895432, 1015.3703350074109, 978.2399396986046, 905.4559512827166, 21236.686244568755, 13429.566923861534, 8004.619760315774, 6835.348441153415, 6414.2058593747215, 6058.724036969387, 3959.2258508715863, 3315.865401210639, 3144.9120304160306, 2222.0136387620946, 1827.096485225, 1808.145278024256, 1666.5468004486017, 1566.4571037251606, 1491.6276456040962, 1478.9334929028319, 1430.122627103455, 1381.9649555692888, 1358.632550984682, 1324.8489041956161, 1217.471322400342, 1204.4820534221578, 1157.9510713798813, 1142.9750255051963, 1113.911564633241, 1094.1397787877988, 900.7090770334482, 887.0830910038807, 863.1997714447704, 783.5345189876298, 14748.886338692948, 8294.333914121593, 7265.99438210499, 5568.971536597262, 4628.6752477519185, 4352.573063250205, 3124.0249292909707, 3030.0695580013576, 3000.0453348390247, 2768.8658308783565, 2558.2601108514054, 2260.245343376863, 2176.556031845306, 2136.237401299015, 1633.2128670000004, 1431.00305451811, 1418.8006541368125, 1334.9442893865678, 1237.6562920862607, 1237.4403227317143, 1209.947872185988, 1171.0842000202954, 1165.098631773442, 1153.6181069819747, 1146.5617895725625, 1127.4842328887798, 1038.2465657963746, 964.5420792040414, 849.3079910417104, 832.8979459553067, 11332.575501851143, 6992.055377978512, 6948.748046798979, 6214.5750837101505, 4749.74450735223, 3855.346398290626, 3010.0143597672704, 2782.5445474361973, 2711.765437468221, 2510.885427765461, 2176.602338902755, 2033.7916448141384, 1995.6613462969583, 1946.9069230288153, 1932.8988817382076, 1871.8076469170462, 1849.0692971232284, 1653.4317097744088, 1481.6964087296617, 1431.91876756756, 1411.4413317500664, 1386.5523149999408, 1381.7294329072245, 1315.3328708488152, 1244.0857014684568, 1147.199757134232, 1010.5906867854509, 972.5759972429971, 902.587252477237, 890.5868054977439, 7233.264460182802, 5936.593754758456, 5547.273359193646, 5423.765741039207, 3346.304720245446, 3325.528031070711, 2866.17854746929, 2500.500794739583, 2399.7103134296367, 2318.1201877867043, 2086.681391923574, 2053.0984088670334, 1898.116625678769, 1896.9678844339214, 1616.4850583447412, 1301.5185209057613, 1149.1885412793245, 1145.0972714903874, 1130.001282395196, 1083.199751768527, 1071.6413099209753, 1060.0718950931682, 1041.7694359825723, 1022.8875327210474, 993.8067752623796, 942.6673187690872, 918.4899496273233, 913.5077446350334, 897.2645481524496, 805.3946868288759, 15146.394366849061, 8714.504243940137, 5096.667089274627, 3387.359741641557, 2924.1574543921415, 2726.4776159826383, 2650.572032584742, 2625.3284054524793, 2286.9747108198326, 2208.9388302450743, 2207.3152384738178, 1793.4985156452851, 1675.8629347993774, 1501.3698568676532, 1450.0821751080098, 1440.43342766831, 1424.562458491924, 1225.620380723815, 1130.5117296901458, 1022.744259819194, 1010.4431972710338, 973.3233141829473, 962.2989914914926, 938.3642953217173, 901.8146878229063, 888.8332039019034, 844.2574547007783, 825.9245329549881, 814.2193828767439, 780.2979616575549, 11877.497917642453, 6017.764278206672, 4203.74488731522, 3984.614367093622, 3302.5664831585555, 2912.0334867324755, 2862.7886860184026, 2736.1541059240535, 2550.7093835260675, 2369.017340282632, 2206.2354237858176, 2091.194430513856, 1791.4284555691745, 1783.3039753452574, 1751.1279196501036, 1640.182054467002, 1441.7410615324898, 1425.57765582177, 1359.7918126272418, 1325.026921183899, 1312.5846865659432, 1280.562721391936, 1243.413911594944, 1132.8585623893155, 910.4057815360417, 798.4296372303929, 773.0952581706109, 749.6494654347475, 749.2914349589341, 731.9289405099635, 9485.404256478547, 5692.938556727514, 5636.651489983513, 4120.009042779571, 2937.654022449724, 2165.2367760840107, 2143.509813618469, 2105.5178655665773, 2062.08294309271, 2012.8587543588735, 1909.2309777287433, 1630.25948025569, 1502.1266936940183, 1475.0663003833997, 1423.1959635924834, 1180.5800790465978, 1043.4117358572926, 1040.3361322671037, 969.8930173503853, 960.9626449124072, 931.7027730684741, 924.3844796774779, 910.9408559816671, 875.3918973633711, 821.0180427236645, 787.81963217356, 739.3753266397504, 721.4126950593618, 710.0458722686542, 705.8687968348264, 24690.51969436023, 14183.431696873486, 12147.074666762188, 9422.690484099872, 5875.347275180898, 4424.497943651013, 3712.6359514822166, 3367.997353924278, 2750.576764854541, 2458.67453200435, 2309.114854429133, 1915.8108449008366, 1588.3173194388187, 1540.7675893035753, 1481.3499931929368, 1264.320276993446, 1168.2502489103172, 781.6407183981169, 655.6995951405702, 570.8173704118594, 512.0219132577656, 426.2643483293264, 416.84174786248116, 391.75434364469055, 367.4468857256827, 348.13652173752655, 344.5592504520676, 338.8104514731779, 322.08764011950245, 321.6142458074596, 7817.5977939352415, 5970.34440795779, 5612.618918743908, 3465.497580772478, 3457.2060765017986, 3309.1616716234403, 3265.9724857997344, 3198.390313963682, 2709.204677509556, 2438.6053525347365, 2073.6448867235126, 2060.8399795054515, 1721.717392379836, 1632.6607491033621, 1337.4264256195938, 1208.637471793458, 1189.4596729229406, 1135.2079657653119, 1079.8259301343062, 1039.3397896920028, 939.3833199341601, 934.5315158571211, 912.4736121399453, 898.2811666080328, 885.64748973703, 823.1812018506527, 816.2234206418924, 803.7738294054017, 800.5930045145784, 775.3078511437905, 12367.505821639359, 4689.502988641729, 4206.275116418604, 4041.2842056900527, 3879.4168573795428, 3549.8681732269592, 3397.4440471258754, 2629.756876907838, 2502.2149346308847, 2232.025749256664, 2075.98979686699, 1597.9474485984185, 1344.690305083115, 1313.8646070215239, 1297.3689147294315, 1221.8778491345934, 982.3623492799231, 960.7233069287178, 958.1894536972832, 896.6350471714765, 824.8978209455731, 748.2347459050989, 709.6673402534236, 696.5647295490025, 657.7139712755077, 635.1925411930514, 589.6188287766915, 583.6962460549038, 552.5353846891343, 541.9189095776953, 8072.502211964212, 4691.755081864201, 4316.20918989873, 3652.9738683065875, 3001.4607011552084, 2952.0431078584697, 2304.7146074747425, 2013.4052636472782, 1922.1748509026952, 1779.482411849637, 1693.999633474193, 1217.8052129919802, 1213.4694600399876, 1204.0307276194565, 1120.4730928922806, 1093.558827720012, 1049.4565345989304, 1042.3320978859958, 1041.8889938015736, 1025.086733089222, 1024.142572650077, 1019.068518031494, 1008.9384611829524, 997.4669887751348, 935.9173697595415, 925.0676790553737, 904.7436640053751, 826.4520956666986, 813.1050211089404, 801.9040781045171, 15525.674543351051, 5409.8198874911905, 4471.013512721405, 2879.9334030620607, 2755.828014494847, 2653.5972682953593, 2400.6942313916975, 2330.886771150085, 1992.9805773957944, 1656.3808587271183, 1517.0110592903295, 1481.3091788769275, 1424.3261704983995, 1313.9823194996616, 1246.8435644213985, 1129.990242748106, 1030.3562727491608, 1019.9122074415277, 989.7213312762344, 919.6457447752215, 896.5925121956976, 894.7685705075452, 856.3492620998425, 828.9402586629847, 818.807416716769, 776.0422327070905, 736.6986471732672, 705.5185468504924, 599.9710818360015, 561.4938585581061], \"Total\": [24691.0, 21237.0, 21725.0, 21359.0, 19497.0, 19910.0, 19357.0, 18478.0, 15526.0, 15147.0, 15652.0, 14184.0, 14749.0, 12368.0, 13430.0, 12148.0, 11878.0, 12268.0, 12410.0, 11509.0, 11333.0, 11597.0, 11470.0, 11369.0, 10853.0, 9486.0, 9423.0, 10297.0, 8715.0, 8073.0, 9474.27341780458, 7792.829887398042, 7427.6910642977855, 6330.722844690934, 5862.772211397139, 5642.923270880496, 5642.286945316094, 5501.508909101079, 5434.790327871922, 5332.598909403935, 4664.765977657131, 4477.22263841175, 4381.194531609959, 4366.453160699569, 4145.87126359582, 3778.422547857095, 3614.7167455263293, 3601.4531096705896, 3567.2578065111807, 3378.8329661810258, 3314.432758504565, 3076.044025493579, 3026.8498400281696, 2704.2846923510883, 2609.5163868080617, 2593.744456320429, 2238.7793893259886, 2063.4661708889953, 2051.587751023615, 1919.8001263823924, 4609.493228042844, 3620.8015980264495, 3496.5218669616042, 3288.5191711616167, 2844.3184707203177, 2766.317242139504, 2700.2339755514795, 2659.198366421278, 2644.589482014338, 2583.4304606619926, 2428.3162133641276, 2339.2136674211943, 2199.749918214846, 2155.9145587612893, 2107.8599847990426, 2028.1286536488617, 2022.5862658889014, 1985.9629755094822, 1905.3577127172261, 1872.352036164415, 1864.4018526788898, 1834.964512675399, 1693.4687287483866, 1579.8628390183064, 1545.0015160200696, 1543.9449276151863, 1418.5704748460728, 1373.731025571033, 1367.0025006630724, 1363.8881070886255, 21359.009467943444, 19910.43168076844, 19357.592505411703, 8860.735634075096, 4022.7884089832205, 3966.815842055612, 3034.33457032972, 2899.567715219349, 2109.579567506764, 1776.2289690353218, 1723.3978910534663, 1705.8903780904768, 1564.4828431732199, 1260.1274448347035, 1215.2427896489853, 1213.423765216748, 1129.055044836558, 1088.0164943471812, 1084.520771083246, 1082.5142652291822, 1023.6720689761258, 1003.0372456870359, 943.8925208429024, 839.4511132082396, 828.6785986959155, 809.6507370059902, 779.8601471336101, 758.8416534790153, 752.0403853930145, 707.3424410519676, 12410.189909796089, 11369.217025305215, 10297.600123042159, 7259.714083292875, 6123.864862850761, 5941.3051101838955, 5200.513875929596, 4818.225218627135, 3651.443540319851, 3397.01506988979, 3128.2280338441515, 2812.743347142814, 2624.483567643503, 2611.227181129394, 2585.3141144815604, 2470.5177736912083, 2202.8250609788324, 2064.110870442861, 2044.400006904473, 1986.2498319811505, 1927.9068201816833, 1863.6309247223894, 1815.055152577354, 1399.4160912448147, 1193.2304121432956, 1180.9075280472937, 1154.737518490316, 1153.9383793529348, 1056.708055047744, 1056.4206525090474, 21725.659364738567, 15652.811114488031, 11597.319423010233, 11470.9010822007, 7280.491790760712, 5560.665029408063, 5218.17873242275, 4966.2530418633905, 4532.579942086229, 4463.0871037924935, 3931.1973771027388, 3177.2719108850356, 2197.4234482141387, 2178.303928025931, 2093.7590595684565, 1679.049150863333, 1569.5080486414124, 1452.0677798966337, 1421.1206275533395, 1240.344189328182, 1215.362693909116, 1192.638291761127, 1182.7034004482966, 986.4325617226964, 981.9159554521957, 815.3035804129088, 777.9275031547863, 761.100418936527, 752.8333803799806, 749.6795211188676, 19497.443746837853, 8759.269850480583, 5843.292344907252, 5739.98861993925, 4810.037275870557, 3329.2047869833314, 3198.9678364234733, 3115.2435901337344, 2448.574638282274, 2383.2743251976317, 2300.8160505232713, 2084.507229733973, 2047.34890181035, 2044.261243499381, 2019.7666296797595, 1909.0323695819216, 1596.1134953712917, 1342.262543437505, 1271.1934639099234, 1072.3021268235898, 1049.3400376105626, 1028.4956901997389, 999.5512199278487, 951.8261717194042, 864.1678045554357, 853.3411485763094, 847.9903747216125, 840.7780725295038, 836.9998027835746, 836.1462404121693, 18478.367395386966, 12268.38806449448, 8455.535242447007, 6145.7268810243595, 4791.390075256534, 4169.585732624386, 2856.094944022746, 2828.5321689587277, 2116.4483372080067, 2098.611459823624, 1775.4989330876626, 1706.2358657400168, 1550.934973314179, 1448.0062701480595, 1325.3903962034244, 1196.3821783598773, 1043.392585324464, 1013.7966136742884, 929.0146466161492, 921.0557000788414, 796.0338722975364, 722.8361375116227, 711.4330366419312, 696.5246547104468, 695.3719012015792, 688.0388733746836, 674.2814731465467, 670.3521892225001, 667.8350896681728, 664.5934645037092, 11509.892221878003, 10853.464116021434, 5790.268577019024, 5717.440929226938, 5309.764635450747, 4161.756163481418, 4081.408766183997, 4069.24099324509, 3013.1459809815656, 2840.2252009462195, 2299.7808801636593, 2110.011661231574, 1807.6356623706843, 1778.9607009240713, 1687.551024176011, 1585.4267108606793, 1521.5065278865272, 1473.2342189689396, 1307.6615431655289, 1210.8833952713774, 1205.8361809682106, 1174.8041572489985, 1170.98933424716, 1150.6267916033264, 1128.4343634536908, 1090.582772374518, 1039.4035786663287, 1016.4736334841963, 979.3432381753901, 906.559249759502, 21237.79158719102, 13430.672266483794, 8005.725102938035, 6836.453783775675, 6415.311201996982, 6059.829379591648, 3960.3311934938483, 3316.970743832901, 3146.0173730382926, 2223.1189813843566, 1828.2018278472622, 1809.2506206465182, 1667.652143070864, 1567.5624463474228, 1492.7329882263584, 1480.038835525094, 1431.2279697257172, 1383.070298191551, 1359.7378936069442, 1325.9542468178784, 1218.5766650226042, 1205.58739604442, 1159.0564140021436, 1144.0803681274585, 1115.0169072555032, 1095.245121410061, 901.8144196557105, 888.1884336261429, 864.3051140670326, 784.639861609892, 14749.991432093988, 8295.439007522633, 7267.099475506032, 5570.076629998303, 4629.78034115296, 4353.678156651247, 3125.130022692014, 3031.1746514024007, 3001.150428240068, 2769.9709242793997, 2559.3652042524486, 2261.350436777906, 2177.661125246349, 2137.342494700058, 1634.3179604010434, 1432.108147919153, 1419.9057475378554, 1336.0493827876107, 1238.7613854873036, 1238.5454161327573, 1211.052965587031, 1172.1892934213383, 1166.203725174485, 1154.7232003830177, 1147.6668829736054, 1128.5893262898228, 1039.3516591974176, 965.6471726050843, 850.4130844427532, 834.0030393563495, 11333.680304439393, 6993.160180566763, 6949.85284938723, 6215.6798862984015, 4750.849309940481, 3856.4512008788784, 3011.119162355523, 2783.6493500244496, 2712.8702400564734, 2511.9902303537133, 2177.7071414910074, 2034.8964474023903, 1996.7661488852102, 1948.0117256170672, 1934.0036843264595, 1872.9124495052981, 1850.1740997114803, 1654.5365123626607, 1482.8012113179136, 1433.023570155812, 1412.5461343383183, 1387.6571175881927, 1382.8342354954764, 1316.4376734370671, 1245.1905040567087, 1148.3045597224839, 1011.6954893737029, 973.6807998312491, 903.6920550654891, 891.6916080859959, 7234.369735572766, 5937.69903014842, 5548.37863458361, 5424.871016429171, 3347.4099956354107, 3326.633306460676, 2867.283822859255, 2501.606070129548, 2400.8155888196015, 2319.225463176669, 2087.786667313539, 2054.2036842569983, 1899.2219010687336, 1898.073159823886, 1617.5903337347058, 1302.623796295726, 1150.293816669289, 1146.202546880352, 1131.1065577851607, 1084.3050271584916, 1072.74658531094, 1061.1771704831328, 1042.874711372537, 1023.9928081110121, 994.9120506523443, 943.7725941590519, 919.595225017288, 914.6130200249981, 898.3698235424143, 806.4999622188407, 15147.49679168994, 8715.606668781016, 5097.769514115507, 3388.4621664824376, 2925.2598792330223, 2727.580040823519, 2651.6744574256227, 2626.43083029336, 2288.0771356607133, 2210.041255085955, 2208.4176633146985, 1794.600940486166, 1676.9653596402584, 1502.4722817085342, 1451.1845999488908, 1441.535852509191, 1425.664883332805, 1226.722805564696, 1131.6141545310268, 1023.8466846600747, 1011.5456221119146, 974.4257390238281, 963.4014163323734, 939.4667201625981, 902.9171126637871, 889.9356287427842, 845.3598795416591, 827.0269577958688, 815.3218077176247, 781.4003864984356, 11878.602678004308, 6018.869038568531, 4204.849647677079, 3985.719127455482, 3303.6712435204154, 2913.1382470943354, 2863.8934463802625, 2737.2588662859134, 2551.8141438879275, 2370.1221006478754, 2207.3401841476775, 2092.299190875716, 1792.533215931034, 1784.4087357071169, 1752.232680011963, 1641.2868148288615, 1442.8458218943492, 1426.6824161836294, 1360.8965729891013, 1326.1316815457585, 1313.6894469278027, 1281.6674817537955, 1244.5186719568035, 1133.963322751175, 911.510541897901, 799.5343975922523, 774.2000185324703, 750.7542257966069, 750.3961953207935, 733.0337008718228, 9486.509018798348, 5694.043319047317, 5637.756252303316, 4121.113805099374, 2938.758784769527, 2166.341538403814, 2144.614575938272, 2106.6226278863805, 2063.1877054125134, 2013.9635166786766, 1910.3357400485463, 1631.364242575493, 1503.2314560138213, 1476.1710627032028, 1424.3007259122865, 1181.6848413664009, 1044.5164981770956, 1041.4408945869068, 970.9977796701883, 962.0674072322101, 932.8075353882771, 925.4892419972808, 912.0456183014701, 876.496659683174, 822.1228050434675, 788.9243944933629, 740.4800889595533, 722.5174573791647, 711.1506345884571, 706.9735591546294, 24691.62767571544, 14184.539678228688, 12148.18264811739, 9423.798465455075, 5876.455256536103, 4425.605925006218, 3713.743932837422, 3369.1053352794834, 2751.6847462097467, 2459.7825133595557, 2310.2228357843387, 1916.9188262560422, 1589.4253007940242, 1541.8755706587808, 1482.4579745481424, 1265.4282583486515, 1169.3582302655227, 782.7486997533225, 656.8075764957758, 571.9253517670651, 513.1298946129713, 427.372329684532, 417.94972921768675, 392.86232499989615, 368.5548670808883, 349.24450309273215, 345.6672318072732, 339.9184328283835, 323.19562147470805, 322.7222271626652, 7818.702509493802, 5971.4491235163505, 5613.723634302468, 3466.6022963310397, 3458.31079206036, 3310.266387182002, 3267.077201358296, 3199.4950295222434, 2710.3093930681175, 2439.710068093298, 2074.749602282074, 2061.944695064013, 1722.8221079383975, 1633.7654646619237, 1338.5311411781554, 1209.7421873520195, 1190.5643884815022, 1136.3126813238734, 1080.9306456928678, 1040.4445052505644, 940.4880354927213, 935.6362314156823, 913.5783276985065, 899.385882166594, 886.7522052955912, 824.2859174092139, 817.3281362004536, 804.8785449639629, 801.6977200731396, 776.4125667023517, 12368.60925644327, 4690.606423445639, 4207.378551222514, 4042.3876404939638, 3880.520292183454, 3550.9716080308704, 3398.5474819297865, 2630.860311711749, 2503.318369434796, 2233.129184060575, 2077.0932316709013, 1599.0508834023296, 1345.793739887026, 1314.968041825435, 1298.4723495333426, 1222.9812839385045, 983.465784083834, 961.8267417326286, 959.292888501194, 897.7384819753873, 826.001255749484, 749.3381807090097, 710.7707750573345, 697.6681643529134, 658.8174060794186, 636.2959759969623, 590.7222635806024, 584.7996808588147, 553.6388194930452, 543.0223443816062, 8073.606920565622, 4692.859790465612, 4317.313898500141, 3654.078576907998, 3002.565409756619, 2953.1478164598802, 2305.819316076153, 2014.5099722486887, 1923.2795595041057, 1780.5871204510474, 1695.1043420756034, 1218.9099215933907, 1214.574168641398, 1205.135436220867, 1121.5778014936911, 1094.6635363214225, 1050.5612432003409, 1043.4368064874063, 1042.9937024029841, 1026.1914416906325, 1025.2472812514875, 1020.1732266329044, 1010.0431697843628, 998.5716973765452, 937.0220783609519, 926.172387656784, 905.8483726067855, 827.556804268109, 814.2097297103508, 803.0087867059275, 15526.777191695504, 5410.922535835643, 4472.116161065858, 2881.036051406514, 2756.9306628393006, 2654.6999166398127, 2401.796879736151, 2331.9894194945387, 1994.0832257402476, 1657.4835070715715, 1518.1137076347827, 1482.4118272213807, 1425.4288188428527, 1315.0849678441148, 1247.9462127658517, 1131.0928910925593, 1031.458921093614, 1021.014855785981, 990.8239796206877, 920.7483931196748, 897.6951605401509, 895.8712188519985, 857.4519104442958, 830.042907007438, 819.9100650612223, 777.1448810515438, 737.8012955177205, 706.6211951949457, 601.0737301804548, 562.5965069025594], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.371799945831299, -3.567199945449829, -3.6150999069213867, -3.7750000953674316, -3.851799964904785, -3.890000104904175, -3.8901000022888184, -3.9154000282287598, -3.9275999069213867, -3.9465999603271484, -4.080399990081787, -4.121500015258789, -4.143099784851074, -4.146500110626221, -4.198400020599365, -4.291200160980225, -4.3354997634887695, -4.339200019836426, -4.348700046539307, -4.4029998779296875, -4.422299861907959, -4.4969000816345215, -4.5131001472473145, -4.625800132751465, -4.661499977111816, -4.667500019073486, -4.814799785614014, -4.896399974822998, -4.902100086212158, -4.968599796295166, -3.703000068664551, -3.944499969482422, -3.9795000553131104, -4.040800094604492, -4.185999870300293, -4.213799953460693, -4.23799991607666, -4.253300189971924, -4.258800029754639, -4.282199859619141, -4.344200134277344, -4.3815999031066895, -4.4430999755859375, -4.463200092315674, -4.485799789428711, -4.524400234222412, -4.527100086212158, -4.545400142669678, -4.5868000984191895, -4.604300022125244, -4.60860013961792, -4.624499797821045, -4.704800128936768, -4.7743000984191895, -4.796599864959717, -4.797299861907959, -4.881999969482422, -4.9141998291015625, -4.919099807739258, -4.92140007019043, -2.0473999977111816, -2.1177000999450684, -2.1458001136779785, -2.927299976348877, -3.7172000408172607, -3.7311999797821045, -3.9992001056671143, -4.0447001457214355, -4.3628997802734375, -4.534999847412109, -4.565199851989746, -4.575399875640869, -4.6620001792907715, -4.878499984741211, -4.91480016708374, -4.916299819946289, -4.988399982452393, -5.0254998207092285, -5.02869987487793, -5.030600070953369, -5.08650016784668, -5.106900215148926, -5.167799949645996, -5.285200119018555, -5.298099994659424, -5.321400165557861, -5.35890007019043, -5.386300086975098, -5.395299911499023, -5.456699848175049, -2.5513999462127686, -2.6389999389648438, -2.738100051879883, -3.0876998901367188, -3.2578001022338867, -3.288100004196167, -3.421299934387207, -3.4976999759674072, -3.7750000953674316, -3.8473000526428223, -3.9296998977661133, -4.036099910736084, -4.105400085449219, -4.110499858856201, -4.1203999519348145, -4.165900230407715, -4.280600070953369, -4.345699787139893, -4.355299949645996, -4.384200096130371, -4.414000034332275, -4.44789981842041, -4.474400043487549, -4.734600067138672, -4.894100189208984, -4.9045000076293945, -4.9268999099731445, -4.927599906921387, -5.015699863433838, -5.015999794006348, -1.9808000326156616, -2.3085999488830566, -2.6085000038146973, -2.619499921798706, -3.074199914932251, -3.3436999320983887, -3.4072999954223633, -3.4567999839782715, -3.5481998920440674, -3.5636000633239746, -3.690500020980835, -3.9035000801086426, -4.27239990234375, -4.281199932098389, -4.320799827575684, -4.541600227355957, -4.609099864959717, -4.686999797821045, -4.708499908447266, -4.844699859619141, -4.865099906921387, -4.883999824523926, -4.892300128936768, -5.073999881744385, -5.07859992980957, -5.264800071716309, -5.311699867248535, -5.333600044250488, -5.344600200653076, -5.348800182342529, -2.0271999835968018, -2.827399969100952, -3.232300043106079, -3.2500998973846436, -3.4268999099731445, -3.7950000762939453, -3.83489990234375, -3.8613998889923096, -4.10230016708374, -4.12939977645874, -4.164599895477295, -4.263400077819824, -4.281400203704834, -4.282899856567383, -4.295000076293945, -4.351399898529053, -4.5304999351501465, -4.70389986038208, -4.758299827575684, -4.928599834442139, -4.950300216674805, -4.970399856567383, -4.998899936676025, -5.047900199890137, -5.144700050354004, -5.157299995422363, -5.163599967956543, -5.172100067138672, -5.176599979400635, -5.177700042724609, -2.0694000720977783, -2.4790000915527344, -2.851300001144409, -3.1703999042510986, -3.4193999767303467, -3.5583999156951904, -3.9368999004364014, -3.9465999603271484, -4.236700057983398, -4.245200157165527, -4.412499904632568, -4.452300071716309, -4.547800064086914, -4.616499900817871, -4.705100059509277, -4.807600021362305, -4.944499969482422, -4.973299980163574, -5.060800075531006, -5.069399833679199, -5.215400218963623, -5.311999797821045, -5.328000068664551, -5.3491997718811035, -5.350800037384033, -5.361499786376953, -5.381700038909912, -5.387499809265137, -5.391300201416016, -5.396200180053711, -2.540800094604492, -2.5994999408721924, -3.2279000282287598, -3.240600109100342, -3.314500093460083, -3.558199882507324, -3.577699899673462, -3.580699920654297, -3.8812999725341797, -3.9403998851776123, -4.151500225067139, -4.23769998550415, -4.392499923706055, -4.4085001945495605, -4.461299896240234, -4.52370023727417, -4.564899921417236, -4.5971999168396, -4.7164998054504395, -4.793399810791016, -4.797599792480469, -4.823699951171875, -4.827000141143799, -4.8445000648498535, -4.863999843597412, -4.898200035095215, -4.946300029754639, -4.968599796295166, -5.005899906158447, -5.083199977874756, -1.9129999876022339, -2.3712000846862793, -2.888700008392334, -3.046600103378296, -3.1101999282836914, -3.1672000885009766, -3.5927000045776367, -3.7699999809265137, -3.8229000568389893, -4.170300006866455, -4.366000175476074, -4.376399993896484, -4.457900047302246, -4.519899845123291, -4.56879997253418, -4.577400207519531, -4.610899925231934, -4.645199775695801, -4.662199974060059, -4.687399864196777, -4.771900177001953, -4.782599925994873, -4.822000026702881, -4.835100173950195, -4.860799789428711, -4.878699779510498, -5.073299884796143, -5.088500022888184, -5.115799903869629, -5.212600231170654, -2.2616000175476074, -2.8371999263763428, -2.969599962234497, -3.235599994659424, -3.4205000400543213, -3.4820001125335693, -3.813699960708618, -3.8441998958587646, -3.8541998863220215, -3.9344000816345215, -4.013500213623047, -4.13730001449585, -4.175099849700928, -4.19379997253418, -4.462299823760986, -4.594399929046631, -4.603000164031982, -4.663899898529053, -4.73960018157959, -4.739799976348877, -4.762199878692627, -4.794899940490723, -4.800000190734863, -4.809899806976318, -4.815999984741211, -4.832799911499023, -4.915299892425537, -4.988900184631348, -5.116099834442139, -5.135700225830078, -2.5169999599456787, -2.9999001026153564, -3.0060999393463135, -3.117799997329712, -3.3866000175476074, -3.5952000617980957, -3.8427000045776367, -3.921299934387207, -3.9470999240875244, -4.02400016784668, -4.166900157928467, -4.234799861907959, -4.253699779510498, -4.27839994430542, -4.285600185394287, -4.317800045013428, -4.329999923706055, -4.441800117492676, -4.551499843597412, -4.585599899291992, -4.599999904632568, -4.617800235748291, -4.621300220489502, -4.670599937438965, -4.72629976272583, -4.807300090789795, -4.934100151062012, -4.972499847412109, -5.0472002029418945, -5.060500144958496, -2.863100051879883, -3.0606000423431396, -3.1284000873565674, -3.1510000228881836, -3.6338999271392822, -3.6401000022888184, -3.788800001144409, -3.925299882888794, -3.966399908065796, -4.000999927520752, -4.106200218200684, -4.122399806976318, -4.200900077819824, -4.201499938964844, -4.361499786376953, -4.578199863433838, -4.702700138092041, -4.706299781799316, -4.7195000648498535, -4.7617998123168945, -4.772600173950195, -4.783400058746338, -4.80079984664917, -4.8190999031066895, -4.8480000495910645, -4.9008002281188965, -4.926799774169922, -4.932199954986572, -4.950099945068359, -5.058199882507324, -2.1070001125335693, -2.6598000526428223, -3.196199893951416, -3.6047000885009766, -3.751800060272217, -3.8217999935150146, -3.8499999046325684, -3.859600067138672, -3.997499942779541, -4.032299995422363, -4.0329999923706055, -4.240600109100342, -4.3084001541137695, -4.418399810791016, -4.453199863433838, -4.459799766540527, -4.470900058746338, -4.621300220489502, -4.702099800109863, -4.802299976348877, -4.8144001960754395, -4.851799964904785, -4.8632001876831055, -4.888400077819824, -4.928100109100342, -4.942599773406982, -4.994100093841553, -5.015999794006348, -5.030300140380859, -5.07289981842041, -2.341399908065796, -3.0213000774383545, -3.380000114440918, -3.4335999488830566, -3.621299982070923, -3.7472000122070312, -3.76419997215271, -3.809499979019165, -3.8796000480651855, -3.9535000324249268, -4.024700164794922, -4.0782999992370605, -4.232999801635742, -4.237599849700928, -4.255799770355225, -4.321199893951416, -4.450200080871582, -4.461400032043457, -4.508699893951416, -4.534599781036377, -4.544000148773193, -4.568699836730957, -4.598199844360352, -4.691299915313721, -4.909900188446045, -5.041100025177002, -5.073400020599365, -5.1041998863220215, -5.104599952697754, -5.1280999183654785, -2.537899971008301, -3.0483999252319336, -3.0583999156951904, -3.371799945831299, -3.710099935531616, -4.015100002288818, -4.025199890136719, -4.043099880218506, -4.064000129699707, -4.088099956512451, -4.140999794006348, -4.298900127410889, -4.380799770355225, -4.39900016784668, -4.434800148010254, -4.621699810028076, -4.745200157165527, -4.7480998039245605, -4.81820011138916, -4.827499866485596, -4.858399868011475, -4.866300106048584, -4.88100004196167, -4.92080020904541, -4.984899997711182, -5.026199817657471, -5.089600086212158, -5.114200115203857, -5.130099773406982, -5.136000156402588, -1.5729999542236328, -2.1273000240325928, -2.2822999954223633, -2.53629994392395, -3.0085999965667725, -3.2922000885009766, -3.4677000045776367, -3.5650999546051025, -3.7676000595092773, -3.8798000812530518, -3.942500114440918, -4.129300117492676, -4.316699981689453, -4.347099781036377, -4.386499881744385, -4.544899940490723, -4.623899936676025, -5.0258002281188965, -5.201499938964844, -5.340099811553955, -5.448800086975098, -5.6321001052856445, -5.6545000076293945, -5.7164998054504395, -5.780600070953369, -5.83459997177124, -5.844900131225586, -5.861700057983398, -5.912300109863281, -5.91379976272583, -2.6600000858306885, -2.9296000003814697, -2.9914000034332275, -3.473599910736084, -3.4760000705718994, -3.519700050354004, -3.532900094985962, -3.553800106048584, -3.7197999954223633, -3.825000047683716, -3.9870998859405518, -3.993299961090088, -4.173099994659424, -4.226200103759766, -4.4257001876831055, -4.526899814605713, -4.542900085449219, -4.589600086212158, -4.639599800109863, -4.677800178527832, -4.7789998054504395, -4.78410005569458, -4.808000087738037, -4.823699951171875, -4.837900161743164, -4.910999774932861, -4.91949987411499, -4.934899806976318, -4.938799858093262, -4.970900058746338, -2.1967999935150146, -3.166599988937378, -3.2753000259399414, -3.3152999877929688, -3.3561999797821045, -3.444999933242798, -3.4888999462127686, -3.744999885559082, -3.7946999073028564, -3.9089999198913574, -3.9814999103546143, -4.243199825286865, -4.4156999588012695, -4.438899993896484, -4.451600074768066, -4.511499881744385, -4.729700088500977, -4.751999855041504, -4.7546000480651855, -4.821000099182129, -4.904399871826172, -5.0019001960754395, -5.054900169372559, -5.073500156402588, -5.130899906158447, -5.1656999588012695, -5.240200042724609, -5.25029993057251, -5.305099964141846, -5.32450008392334, -2.6131999492645264, -3.155900001525879, -3.239300012588501, -3.4061999320983887, -3.60260009765625, -3.6191999912261963, -3.8666999340057373, -4.0019001960754395, -4.0482001304626465, -4.125400066375732, -4.174600124359131, -4.5046000480651855, -4.508200168609619, -4.515999794006348, -4.587900161743164, -4.612299919128418, -4.65339994430542, -4.660200119018555, -4.660699844360352, -4.6768999099731445, -4.677800178527832, -4.682799816131592, -4.692800045013428, -4.70419979095459, -4.767899990081787, -4.779600143432617, -4.801799774169922, -4.892300128936768, -4.908599853515625, -4.922500133514404, -1.9384000301361084, -2.9927000999450684, -3.183300018310547, -3.6231000423431396, -3.6672000885009766, -3.7049999237060547, -3.8050999641418457, -3.834700107574463, -3.991300106048584, -4.176300048828125, -4.264200210571289, -4.288000106811523, -4.327199935913086, -4.407800197601318, -4.460299968719482, -4.558700084686279, -4.651000022888184, -4.661200046539307, -4.691199779510498, -4.764699935913086, -4.79010009765625, -4.792099952697754, -4.835999965667725, -4.868500232696533, -4.880799770355225, -4.934500217437744, -4.986499786376953, -5.029699802398682, -5.191800117492676, -5.2581000328063965], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.3404, 2.3403, 2.3403, 2.3403, 2.3403, 2.3403, 2.3403, 2.3403, 2.3403, 2.3403, 2.3402, 2.3402, 2.3402, 2.3402, 2.3402, 2.3402, 2.3402, 2.3402, 2.3402, 2.3402, 2.3401, 2.3401, 2.3401, 2.3401, 2.3401, 2.3401, 2.34, 2.3399, 2.3399, 2.3399, 2.7295, 2.7295, 2.7295, 2.7294, 2.7294, 2.7294, 2.7294, 2.7294, 2.7294, 2.7293, 2.7293, 2.7293, 2.7293, 2.7293, 2.7292, 2.7292, 2.7292, 2.7292, 2.7292, 2.7292, 2.7292, 2.7292, 2.7291, 2.7291, 2.7291, 2.7291, 2.729, 2.729, 2.729, 2.729, 2.8518, 2.8518, 2.8518, 2.8517, 2.8516, 2.8516, 2.8515, 2.8515, 2.8513, 2.8512, 2.8512, 2.8512, 2.8511, 2.851, 2.8509, 2.8509, 2.8509, 2.8508, 2.8508, 2.8508, 2.8508, 2.8507, 2.8507, 2.8505, 2.8505, 2.8505, 2.8504, 2.8504, 2.8504, 2.8503, 2.8907, 2.8907, 2.8907, 2.8907, 2.8907, 2.8906, 2.8906, 2.8906, 2.8905, 2.8905, 2.8905, 2.8904, 2.8904, 2.8904, 2.8904, 2.8904, 2.8903, 2.8903, 2.8903, 2.8903, 2.8903, 2.8902, 2.8902, 2.89, 2.8899, 2.8899, 2.8899, 2.8899, 2.8898, 2.8898, 2.9014, 2.9014, 2.9014, 2.9014, 2.9013, 2.9013, 2.9013, 2.9013, 2.9013, 2.9012, 2.9012, 2.9011, 2.901, 2.901, 2.901, 2.9008, 2.9008, 2.9007, 2.9007, 2.9006, 2.9006, 2.9006, 2.9006, 2.9004, 2.9004, 2.9001, 2.9001, 2.9, 2.9, 2.9, 2.9632, 2.9632, 2.9631, 2.9631, 2.9631, 2.963, 2.963, 2.9629, 2.9629, 2.9628, 2.9628, 2.9628, 2.9628, 2.9628, 2.9628, 2.9627, 2.9626, 2.9625, 2.9624, 2.9623, 2.9623, 2.9622, 2.9622, 2.9621, 2.962, 2.962, 2.962, 2.962, 2.962, 2.962, 2.9747, 2.9747, 2.9746, 2.9746, 2.9745, 2.9745, 2.9744, 2.9744, 2.9742, 2.9742, 2.9741, 2.9741, 2.974, 2.974, 2.9739, 2.9738, 2.9737, 2.9737, 2.9736, 2.9735, 2.9734, 2.9732, 2.9732, 2.9732, 2.9732, 2.9731, 2.9731, 2.9731, 2.9731, 2.9731, 2.9767, 2.9767, 2.9766, 2.9766, 2.9766, 2.9765, 2.9765, 2.9765, 2.9764, 2.9764, 2.9763, 2.9763, 2.9762, 2.9762, 2.9762, 2.9761, 2.9761, 2.9761, 2.976, 2.9759, 2.9759, 2.9759, 2.9759, 2.9759, 2.9758, 2.9758, 2.9758, 2.9757, 2.9757, 2.9756, 2.9919, 2.9919, 2.9919, 2.9918, 2.9918, 2.9918, 2.9917, 2.9917, 2.9916, 2.9915, 2.9914, 2.9914, 2.9913, 2.9913, 2.9913, 2.9912, 2.9912, 2.9912, 2.9912, 2.9912, 2.9911, 2.9911, 2.991, 2.991, 2.991, 2.991, 2.9908, 2.9908, 2.9907, 2.9906, 3.0078, 3.0078, 3.0077, 3.0077, 3.0076, 3.0076, 3.0075, 3.0075, 3.0075, 3.0075, 3.0075, 3.0074, 3.0074, 3.0074, 3.0072, 3.0071, 3.0071, 3.0071, 3.007, 3.007, 3.007, 3.0069, 3.0069, 3.0069, 3.0069, 3.0069, 3.0068, 3.0067, 3.0066, 3.0066, 3.0159, 3.0159, 3.0159, 3.0159, 3.0158, 3.0157, 3.0157, 3.0156, 3.0156, 3.0156, 3.0155, 3.0155, 3.0155, 3.0155, 3.0155, 3.0154, 3.0154, 3.0154, 3.0153, 3.0153, 3.0153, 3.0152, 3.0152, 3.0152, 3.0151, 3.0151, 3.0149, 3.0149, 3.0148, 3.0148, 3.1188, 3.1188, 3.1188, 3.1187, 3.1186, 3.1186, 3.1186, 3.1185, 3.1185, 3.1185, 3.1184, 3.1184, 3.1184, 3.1184, 3.1183, 3.1181, 3.118, 3.118, 3.118, 3.1179, 3.1179, 3.1179, 3.1179, 3.1179, 3.1178, 3.1178, 3.1178, 3.1177, 3.1177, 3.1176, 3.1358, 3.1358, 3.1357, 3.1356, 3.1355, 3.1355, 3.1355, 3.1355, 3.1354, 3.1354, 3.1354, 3.1353, 3.1353, 3.1352, 3.1352, 3.1352, 3.1351, 3.135, 3.1349, 3.1348, 3.1348, 3.1348, 3.1348, 3.1347, 3.1347, 3.1347, 3.1346, 3.1346, 3.1346, 3.1345, 3.1446, 3.1445, 3.1444, 3.1444, 3.1443, 3.1443, 3.1443, 3.1443, 3.1442, 3.1442, 3.1442, 3.1441, 3.1441, 3.1441, 3.144, 3.144, 3.1439, 3.1439, 3.1439, 3.1438, 3.1438, 3.1438, 3.1438, 3.1437, 3.1435, 3.1433, 3.1432, 3.1432, 3.1432, 3.1432, 3.1729, 3.1728, 3.1728, 3.1728, 3.1726, 3.1725, 3.1725, 3.1725, 3.1725, 3.1725, 3.1724, 3.1723, 3.1723, 3.1723, 3.1722, 3.1721, 3.172, 3.172, 3.1719, 3.1719, 3.1718, 3.1718, 3.1718, 3.1718, 3.1717, 3.1716, 3.1715, 3.1715, 3.1715, 3.1715, 3.1812, 3.1812, 3.1812, 3.1812, 3.1811, 3.181, 3.181, 3.181, 3.1809, 3.1808, 3.1808, 3.1807, 3.1806, 3.1806, 3.1805, 3.1804, 3.1803, 3.1799, 3.1796, 3.1793, 3.1791, 3.1787, 3.1786, 3.1785, 3.1783, 3.1781, 3.1781, 3.178, 3.1779, 3.1778, 3.2441, 3.2441, 3.2441, 3.244, 3.244, 3.2439, 3.2439, 3.2439, 3.2439, 3.2438, 3.2437, 3.2437, 3.2436, 3.2436, 3.2434, 3.2434, 3.2433, 3.2433, 3.2433, 3.2432, 3.2431, 3.2431, 3.2431, 3.243, 3.243, 3.2429, 3.2429, 3.2429, 3.2429, 3.2429, 3.2487, 3.2486, 3.2485, 3.2485, 3.2485, 3.2485, 3.2485, 3.2484, 3.2484, 3.2483, 3.2483, 3.2481, 3.248, 3.248, 3.248, 3.2479, 3.2477, 3.2477, 3.2477, 3.2476, 3.2475, 3.2473, 3.2472, 3.2472, 3.2471, 3.2471, 3.2469, 3.2469, 3.2468, 3.2468, 3.2589, 3.2588, 3.2587, 3.2587, 3.2586, 3.2586, 3.2585, 3.2584, 3.2584, 3.2584, 3.2583, 3.2581, 3.2581, 3.2581, 3.258, 3.258, 3.2579, 3.2579, 3.2579, 3.2579, 3.2579, 3.2579, 3.2579, 3.2579, 3.2578, 3.2578, 3.2578, 3.2577, 3.2576, 3.2576, 3.2797, 3.2796, 3.2795, 3.2794, 3.2794, 3.2794, 3.2793, 3.2793, 3.2792, 3.2791, 3.2791, 3.279, 3.279, 3.279, 3.2789, 3.2788, 3.2787, 3.2787, 3.2787, 3.2786, 3.2786, 3.2786, 3.2785, 3.2785, 3.2784, 3.2784, 3.2783, 3.2782, 3.278, 3.2778]}, \"token.table\": {\"Topic\": [18, 11, 13, 9, 11, 14, 5, 7, 2, 4, 18, 13, 20, 16, 1, 6, 5, 17, 2, 14, 3, 16, 4, 16, 1, 20, 7, 14, 9, 19, 2, 19, 17, 18, 16, 6, 1, 13, 7, 9, 17, 4, 1, 16, 8, 16, 6, 18, 18, 15, 20, 5, 5, 14, 16, 9, 13, 15, 4, 16, 10, 10, 14, 9, 5, 7, 2, 5, 20, 18, 7, 2, 18, 2, 5, 2, 13, 15, 13, 6, 1, 19, 14, 2, 5, 11, 6, 10, 20, 13, 10, 14, 12, 14, 12, 8, 1, 14, 17, 16, 8, 12, 15, 8, 8, 17, 12, 12, 8, 10, 15, 18, 6, 3, 11, 9, 17, 2, 16, 4, 12, 14, 9, 7, 14, 9, 3, 15, 4, 16, 8, 12, 16, 4, 1, 10, 15, 1, 10, 14, 9, 15, 19, 19, 9, 18, 8, 20, 11, 7, 4, 20, 11, 19, 4, 3, 20, 16, 11, 4, 1, 19, 17, 13, 19, 3, 14, 20, 8, 7, 9, 18, 8, 9, 13, 6, 11, 19, 11, 4, 7, 12, 3, 6, 12, 19, 3, 10, 5, 11, 7, 9, 1, 3, 13, 10, 10, 10, 11, 18, 18, 7, 11, 6, 2, 7, 12, 1, 5, 15, 12, 16, 6, 14, 14, 7, 8, 3, 4, 4, 9, 1, 19, 1, 9, 2, 10, 8, 2, 18, 7, 2, 16, 2, 15, 8, 13, 6, 11, 15, 15, 3, 8, 18, 5, 17, 1, 13, 1, 4, 16, 15, 2, 13, 3, 8, 14, 9, 15, 16, 6, 1, 7, 5, 15, 8, 1, 2, 13, 19, 7, 1, 16, 7, 11, 12, 9, 17, 2, 7, 1, 11, 19, 11, 14, 8, 20, 9, 15, 19, 1, 18, 5, 15, 20, 6, 20, 9, 11, 13, 4, 6, 10, 5, 17, 20, 3, 3, 5, 20, 7, 19, 8, 14, 17, 10, 2, 17, 3, 15, 15, 8, 17, 8, 14, 1, 12, 3, 19, 19, 15, 4, 20, 20, 16, 12, 10, 20, 11, 18, 17, 17, 17, 8, 8, 5, 11, 2, 8, 6, 14, 17, 18, 1, 7, 6, 6, 11, 6, 4, 5, 1, 2, 13, 3, 13, 5, 12, 6, 13, 3, 4, 12, 16, 4, 16, 5, 17, 12, 18, 7, 11, 9, 10, 15, 8, 19, 17, 13, 5, 2, 6, 13, 19, 7, 12, 12, 3, 20, 16, 18, 3, 13, 19, 3, 9, 2, 7, 5, 7, 12, 7, 17, 19, 18, 18, 12, 11, 8, 17, 14, 6, 16, 15, 11, 17, 13, 1, 20, 17, 16, 13, 3, 12, 13, 10, 19, 5, 15, 15, 15, 11, 9, 9, 18, 6, 4, 3, 15, 15, 20, 1, 11, 9, 5, 15, 17, 12, 11, 10, 1, 4, 7, 12, 11, 6, 17, 19, 12, 1, 8, 9, 20, 16, 11, 8, 12, 18, 20, 13, 5, 2, 8, 3, 6, 6, 18, 10, 6, 1, 4, 10, 14, 14, 14, 3, 10, 4, 13, 2, 10, 5, 7, 14, 4, 19, 16, 20, 18, 1, 6, 2, 2, 14, 10, 8, 9, 12, 5, 3, 9, 2, 10, 11, 17, 19, 5, 19, 3, 10, 17, 10, 17, 7, 10, 20, 6, 12, 13, 7, 20, 13, 20, 18, 4, 6, 9, 12, 20, 16, 2, 5, 5, 5, 15, 7, 17, 19, 19, 19, 12, 3, 10, 13, 19, 18, 16, 10, 14, 20, 18, 6, 17, 20, 10, 20, 14, 4, 3, 9, 14, 16, 4, 9, 18, 16, 2, 11, 4, 18, 13, 2, 1, 3, 4, 3, 14, 15, 8, 4], \"Freq\": [0.9996723491348043, 0.9995128178545991, 0.9989345721048022, 0.9990556886058392, 0.9996792179575624, 0.9993411894725166, 0.9988787759275933, 0.9988432544137857, 0.9992778942536977, 0.9994186663827511, 0.9991404463020654, 0.9989486557088337, 0.9990476147076977, 0.9977620780290997, 0.9997001631978892, 0.9993411470760273, 0.9999696504153224, 0.9999101501185205, 0.9993517702023688, 0.9992105308167758, 0.9990544253469608, 0.9978050198631381, 0.9994347201629328, 0.9977276472472791, 0.9998935062859021, 0.9990337742362578, 0.9992756770826167, 0.9992159719939043, 0.9996638681391002, 0.9987437413853643, 0.9993879784192524, 0.9990578351720969, 0.9986116460385204, 0.9994736723156034, 0.9996818770133922, 0.9984283559060209, 0.9998545798781107, 0.9998490488608054, 0.999214227327707, 0.9999627274244702, 0.999129696822543, 0.9999041183249622, 0.9997898478895207, 0.9967889131110921, 0.9992704538894273, 0.9987704519182248, 0.9996381156881542, 0.999410206881262, 0.9991976296355539, 0.9988535460502322, 0.9990275177573905, 0.9994014021601143, 0.9997741103777404, 0.9993790606614095, 0.9988713241234906, 0.9990032637289421, 0.9989842781237346, 0.9997418009353269, 0.9993707579172435, 0.9996719202371298, 0.9993718860204263, 0.9999327842257704, 0.9998650785746647, 0.9990879893848371, 0.9996514254339878, 0.99890782495212, 0.9991327098496398, 0.9992114479716835, 0.998890042822984, 0.9987878278119862, 0.9979828674475302, 0.999523828243761, 0.9981173069723853, 0.9992874237167308, 0.9993751517858822, 0.9995151090320628, 0.9985368417861618, 0.9997297320209901, 0.9994207169726018, 0.9986291388314988, 0.9995249418987867, 0.9986230057455582, 0.9994792083256399, 0.9994538519439811, 0.9999481809061581, 0.9993967205366611, 0.9987856716954885, 0.999649482140448, 0.9971622523727544, 0.9995288526476332, 0.9987973193033881, 0.9994751827158123, 0.9991813767809815, 0.9985898317217975, 0.9989508426031464, 0.9996604545370411, 0.9998682856216659, 0.9995400996590353, 0.9984178049729875, 0.9999152713783087, 0.9986284296219856, 0.9995522512110522, 0.9982924524963791, 0.9993154967625569, 0.9991551295829726, 0.9993864913038669, 0.9990168501248187, 0.999304043171833, 0.9993065550848382, 0.9996964058187546, 0.9997134329192913, 0.9986325559247223, 0.9996204365056368, 0.998897049507182, 0.9996057984853015, 0.9984899845600921, 0.9997573246482762, 0.999549350497349, 0.9991032602832532, 0.9996046658523099, 0.9990832851489272, 0.9991446652606447, 0.9996089453825405, 0.998490094942473, 0.998342814670299, 0.9994573265844737, 0.999794333266757, 0.9983820100376863, 0.9996074346783976, 0.9990165154269639, 0.9990098446119584, 0.9988752293974461, 0.9999026481448586, 0.9996254532448138, 0.9992260867112202, 0.9993621072811164, 0.9986164413224062, 0.9997257281364059, 0.9998067118156858, 0.9992965089476845, 0.9987061421182105, 0.9991807941425821, 0.9990634496540033, 0.9996113244133996, 0.9992803320173616, 0.998652248425177, 0.9994552607258058, 0.998213646468741, 0.9998906175493528, 0.9976023470154056, 0.9995300366286539, 0.9991683895044575, 0.9994596637015143, 0.9989092270240422, 0.9986552208103152, 0.9991962744227263, 0.9990060323018515, 0.9997996811705718, 0.9989079061879826, 0.9991868028919698, 0.99959652128562, 0.9990472594410736, 0.9995228132175635, 0.9982078502613609, 0.9994786425795981, 0.999560176935408, 0.9989953758890846, 0.9983067150161885, 0.9996196729302865, 0.9978110542101619, 0.9988631573099745, 0.9998707153423473, 0.9998183066350562, 0.9994966614950767, 0.9994552187413973, 0.9990593915894639, 0.9992857269223417, 0.9992534956215623, 0.9996236952567823, 0.9989688394372337, 0.9999260002056617, 0.9990217033244618, 0.9999280939363147, 0.9990745803739114, 0.998796439077746, 0.9993938445016153, 0.9982713547157098, 0.9996124765025145, 0.999921446258298, 0.9997667270755766, 0.9998817257846905, 0.9997956136568131, 0.9994189012126049, 0.9985977483107796, 0.999569310322831, 0.9991935716103126, 0.9993737023879161, 0.9998487050425362, 0.9992243864585869, 0.9985095728722281, 0.9996082246531435, 0.9994583165871181, 0.9998340978131764, 0.9998277662196374, 0.9996760537506033, 0.9996196906057169, 0.9982652965414669, 0.9996518686344422, 0.9984011104032579, 0.9988905068146098, 0.9993297492911468, 0.9996371287833957, 0.9993569163636447, 0.998449989016088, 0.9995216761797241, 0.9993971550514584, 0.9994599650663603, 0.9993434723907256, 0.9996614540389839, 0.9995296348494697, 0.9986619577770328, 0.9995677213541628, 0.9998167875231733, 0.9997269203453809, 0.9992261433182749, 0.9995647483357721, 0.9994665848194778, 0.9991622384594058, 0.9995920104725909, 0.9997263824839734, 0.9997086360027427, 0.9993488416798932, 0.9983820410055158, 0.9994743698481707, 0.9991637412786862, 0.999568625422445, 0.9999303928224309, 0.998545749667217, 0.9988639253310994, 0.9983908597423922, 0.9986342611631992, 0.9990657362710378, 0.9985486912001443, 0.998915578574158, 0.9985477347582742, 0.9982723674033701, 0.9996474024084032, 0.999358063767444, 0.9997534751823002, 0.9993613107061072, 0.9994706849203473, 0.9993807355026749, 0.9995757908134287, 0.9995292397953174, 0.9991052930087945, 0.9987288906646721, 0.9996092711715722, 0.9999499454330762, 0.9994204534555855, 0.9988384823141714, 0.9994653048605615, 0.9997273502462991, 0.9998184334399908, 0.9995996845971293, 0.9995215818604969, 0.9997809122319371, 0.9992894621149211, 0.999778613104102, 0.9991079128233754, 0.9985932304548201, 0.9979857041097004, 0.9996605947493189, 0.9977980339387096, 0.9987012207224896, 0.9994810328777585, 0.9995211232149299, 0.9991420166795982, 0.9995377905528028, 0.9988929172896798, 0.9988447016472844, 0.9997129800822842, 0.99890542736925, 0.9996446746410524, 0.999877285259744, 0.9997979362525963, 0.9996950307816248, 0.9994567800750415, 0.9993426175223349, 0.9980011765588013, 0.9993346991612412, 0.9998655920355659, 0.997963249736207, 0.9996954166916897, 0.999206689026231, 0.9996624279123719, 0.9999259519936767, 0.9997363481139899, 0.9991845155450308, 0.9999399749753726, 0.9994243413349543, 0.9997357216599342, 0.99913201407573, 0.9998314517978263, 0.9997476886794072, 0.9983750269425108, 0.9985268113070568, 0.9981021341657781, 0.9991888750353456, 0.9998804046989801, 0.9989139412974896, 0.9993050650616613, 0.9984260545530437, 0.9985502491794647, 0.9994137822063076, 0.9988561034322984, 0.9987522329721402, 0.9994434999738152, 0.9986860110241518, 0.9990521831673065, 0.998828285067853, 0.9998409300201626, 0.9998651015007022, 0.9995314721246834, 0.9996483459671013, 0.9991504815615749, 0.9996671988348237, 0.9998394401587554, 0.9994593279504664, 0.9993485108567115, 0.9988499731199801, 0.9998167700895729, 0.999329942603956, 0.9991749827040504, 0.9999499450732171, 0.9999745794111395, 0.9991612498001935, 0.9998442336280161, 0.9987435504856033, 0.9993007977240929, 0.9988461439650671, 0.9989084751116055, 0.9996387022890619, 0.9988447886348113, 0.9991001092318517, 0.9997479765432167, 0.9990935845254871, 0.9995594628888685, 0.9992666431388486, 0.9986496307159827, 0.999855027815987, 0.9991466295832406, 0.999670285918604, 0.9996567275042939, 0.9997719106935598, 0.998749557067168, 0.9988054922112889, 0.9996453212663021, 0.9990439181371604, 0.9997843518020618, 0.9998587717282909, 0.9992646487227271, 0.9999069610876646, 0.9993989683369959, 0.9991730356968868, 0.9986165830808796, 0.9983787901843018, 0.999352219429853, 0.9988906937353383, 0.99938303213281, 0.9990200939302122, 0.9999177322587374, 0.9997011876989339, 0.9997577275907727, 0.9963006260132716, 0.9998446120432878, 0.9964365850236397, 0.9994648069196366, 0.9981806493571437, 0.999660286769463, 0.9987773212131459, 0.9998868584456913, 0.9993654112271578, 0.9996766155689375, 0.99932980427692, 0.9985481338210146, 0.9998559944737208, 0.9988389674263219, 0.9997089539029311, 0.9999011855417087, 0.9998862303466769, 0.9995380379184227, 0.9988320920247029, 0.9985453453683839, 0.9987039337061162, 0.9996166289832075, 0.9995787801203769, 0.9984752119822848, 0.999478056678253, 0.999225616255152, 0.9997511538301436, 0.9982141832039793, 0.9993081021328071, 0.9994572756724828, 0.9981187946735743, 0.9989658951434794, 0.9986833007298945, 0.9994462941101864, 0.9980994982101961, 0.9994052604837105, 0.9991557679592317, 0.9990304540196493, 0.9980270971559123, 0.9991390329281753, 0.9997048293064046, 0.999342808028664, 0.9994733512720982, 0.9996232051263402, 0.9992341914907741, 0.9990809023527046, 0.9991517299972877, 0.9980808860796071, 0.9987229710460548, 0.9980697279178455, 0.9989724181753257, 0.9990713336628234, 0.9993200013057215, 0.9991837014057808, 0.9998017146081456, 0.9989976217514582, 0.99953272953749, 0.9998914537754756, 0.9987582535415704, 0.9988908707433801, 0.999882272552908, 0.9984720193749763, 0.998699516967663, 0.9987834337390634, 0.9990391583893323, 0.9991342958138294, 0.9994243347760373, 0.998622919991812, 0.9994806367930117, 0.9992981025226101, 0.9990969099207557, 0.9990422891754949, 0.9992769371521127, 0.9993151991294538, 0.9992512406115922, 0.9990867617430629, 0.9978997637168947, 0.999187190414594, 0.9998858195645794, 0.999675281640247, 0.9997073402487177, 0.9997564233528918, 0.9998658593473234, 0.9984399619330443, 0.9981401583520054, 0.999628323458761, 0.9985917585318235, 0.9998363842930028, 0.9997457116320759, 0.9997098805910809, 0.9994716067083057, 0.9995264553614406, 0.9993023708060105, 0.9998710954885548, 0.9991086533015888, 0.9994346056587273, 0.9997192328417053, 0.9996548333517413, 0.999088556873176, 0.9992417840158715, 0.9972980787751301, 0.9996163051513879, 0.9995205423504704, 0.9998106627636086, 0.9994943489751356, 0.9991049642031175, 0.9983913602069732, 0.9996374656553783, 0.9995364546080581, 0.9982800354638535, 0.999065550575782, 0.9984480836029986, 0.9997788327485654, 0.9995446637311927, 0.9996384077834175, 0.9996008048495235, 0.999623507471947, 0.9992314994817635, 0.9991305371301241, 0.9998195739758658, 0.9987797113928266, 0.9995265642020853, 0.9988266545805672, 0.9992262121259745, 0.9994618164853603, 0.9995336328048913, 0.9994579728303571, 0.9993853654979694, 0.9990671753044548, 0.9988538151615033, 0.9996809548650408, 0.9999016375459581, 0.9999248265897023, 0.9995206754488208, 0.9996403892946746, 0.9987592828120877, 0.9995832241224507, 0.9986486368165075, 0.9992480952124804, 0.9995430116194922, 0.9981393891260382, 0.9994189228743121, 0.9994941021482306, 0.9995089622644239, 0.9998096254073312, 0.9989162771593988, 0.9991811074921164, 0.9997873482624683, 0.9994811643595891, 0.9992145628738504, 0.999312550682485, 0.9996209733192952, 0.9989672027735353, 0.9997950975286305, 0.9985138960622754, 0.9989773322174211, 0.9998265302750912, 0.9996174364737214, 0.9983383552433472, 0.9995168842821168, 0.9986653294799569, 0.998967825990862, 0.9997504176936244, 0.9996974535309628, 0.9997515247832913, 0.9994107832988698, 0.9993156756144035, 0.9992663872085591, 0.999745648481195, 0.9995757187034094, 0.9999507417179541, 0.999491700264119, 0.9994592183986133, 0.9993087631794918, 0.9994140385073675, 0.999829504889502, 0.9957811788155085, 0.9994678539266965, 0.9988077254615308, 0.9988930081984941, 0.9985541737868643, 0.9997044426096356, 0.9989509534644229, 0.9984590794740346, 0.9996956676000333, 0.9985142283785026, 0.9992504518371765, 0.9993566306980527, 0.9999527380731321, 0.9989854083909374, 0.9995684867026402, 0.9987341582707403, 0.9996729922497521, 0.999752358101513, 0.9994028184416077, 0.9993928511077258, 0.9985855751850329, 0.9991773974378793, 0.9990611469113029, 0.999541842675861, 0.9996682151838592, 0.9996166709175113, 0.9991208936284818, 0.9996880308583437, 0.9993856455082529, 0.9986011590998649, 0.9999094269502498, 0.9997968189111638, 0.9994321392235258, 0.9998929543430733, 0.9998631348277822, 0.9992638286295603, 0.9990434992053536, 0.9992157239888089, 0.9998212298717402, 0.9997803327451307, 0.9988660909615275, 0.9984387736881789, 0.9996590893316389, 0.9998357950514989, 0.9999169782165415, 0.9997088987808296, 0.9998040143047395, 0.9998556143084419, 0.9993007825689779, 0.9999224821691808, 0.9989880842062099], \"Term\": [\"about\", \"accord\", \"act\", \"activity\", \"actor\", \"actress\", \"add\", \"adult\", \"again\", \"age\", \"ago\", \"agree\", \"air\", \"airline\", \"album\", \"allow\", \"also\", \"american\", \"ancient\", \"animal\", \"announce\", \"apart\", \"appear\", \"arda_che_partement_southern\", \"area\", \"around\", \"art\", \"article\", \"as\", \"asteroid\", \"attack\", \"author\", \"available\", \"award\", \"back\", \"ball\", \"band\", \"base\", \"battle\", \"bear\", \"beat\", \"become\", \"begin\", \"beginning\", \"believe\", \"belong\", \"big\", \"bird\", \"black\", \"blood\", \"blue\", \"body\", \"book\", \"border\", \"branch\", \"brazilian\", \"bring\", \"british\", \"brother\", \"build\", \"building\", \"call\", \"can\", \"canadian\", \"capital\", \"capture\", \"car\", \"career\", \"carry\", \"case\", \"catch\", \"cause\", \"celebrate\", \"cell\", \"center\", \"central\", \"certain\", \"change\", \"character\", \"charge\", \"child\", \"choose\", \"christian\", \"church\", \"city\", \"claim\", \"class\", \"close\", \"cloud\", \"club\", \"coach\", \"coast\", \"code\", \"collection\", \"college\", \"color\", \"come\", \"common\", \"commonly\", \"commune\", \"community\", \"company\", \"compete\", \"complete\", \"complex\", \"composer\", \"computer\", \"connect\", \"consider\", \"contain\", \"continue\", \"contract\", \"control\", \"copy\", \"could\", \"council\", \"country\", \"county\", \"cover\", \"create\", \"culture\", \"current\", \"currently\", \"cut\", \"damage\", \"daughter\", \"day\", \"dead\", \"death\", \"decide\", \"defeat\", \"degree\", \"department\", \"describe\", \"design\", \"develop\", \"development\", \"die\", \"different\", \"direct\", \"director\", \"discover\", \"distance\", \"district\", \"division\", \"double\", \"driver\", \"dry\", \"early\", \"earthquake\", \"east\", \"eastern\", \"eat\", \"effect\", \"election\", \"element\", \"emperor\", \"end\", \"energy\", \"engine\", \"english\", \"enter\", \"episode\", \"european\", \"even\", \"event\", \"eventually\", \"ever\", \"example\", \"expensive\", \"fall\", \"family\", \"famous\", \"father\", \"feature\", \"few\", \"field\", \"fight\", \"film\", \"final\", \"find\", \"finish\", \"first\", \"fish\", \"flag\", \"flow\", \"fly\", \"follow\", \"football\", \"force\", \"form\", \"former\", \"found\", \"free\", \"french\", \"friend\", \"full\", \"game\", \"generally\", \"genus\", \"german\", \"get\", \"give\", \"go\", \"good\", \"government\", \"graduate\", \"great\", \"greek\", \"green\", \"ground\", \"group\", \"grow\", \"guitar\", \"half\", \"hand\", \"happen\", \"hard\", \"have\", \"head\", \"heart\", \"help\", \"high\", \"history\", \"hit\", \"hold\", \"home\", \"house\", \"how\", \"however\", \"human\", \"hurricane\", \"husband\", \"idea\", \"image\", \"important\", \"include\", \"increase\", \"independent\", \"industry\", \"influence\", \"information\", \"instead\", \"instruction\", \"introduce\", \"involve\", \"island\", \"italian\", \"japanese\", \"job\", \"join\", \"just\", \"keep\", \"kill\", \"kind\", \"king\", \"km\", \"know\", \"label\", \"lake\", \"land\", \"language\", \"large\", \"last\", \"late\", \"later\", \"law\", \"lead\", \"leader\", \"league\", \"least\", \"leave\", \"leg\", \"length\", \"less\", \"letter\", \"level\", \"life\", \"light\", \"like\", \"line\", \"link\", \"list\", \"live\", \"locate\", \"long\", \"look\", \"lose\", \"loss\", \"low\", \"lrb\", \"machine\", \"main\", \"mainly\", \"major\", \"make\", \"man\", \"manager\", \"many\", \"marry\", \"match\", \"material\", \"may\", \"mean\", \"meaning\", \"measure\", \"medical\", \"meet\", \"member\", \"merge\", \"metal\", \"method\", \"middle\", \"mile\", \"military\", \"model\", \"modern\", \"money\", \"month\", \"moon\", \"more\", \"most\", \"mostly\", \"mother\", \"mountain\", \"move\", \"movie\", \"much\", \"municipality\", \"municipality_locate_belgian\", \"music\", \"musician\", \"must\", \"name\", \"nan\", \"nation\", \"national\", \"native\", \"natural\", \"ndash\", \"nearby\", \"need\", \"network\", \"never\", \"new\", \"newspaper\", \"next\", \"night\", \"non\", \"north\", \"northern\", \"northwest\", \"now\", \"number\", \"occupy\", \"occur\", \"official\", \"officially\", \"often\", \"old\", \"one\", \"only\", \"open\", \"opera\", \"operation\", \"orchestra\", \"order\", \"organization\", \"original\", \"originally\", \"other\", \"own\", \"page\", \"parallel\", \"part\", \"partement\", \"party\", \"past\", \"pay\", \"peak\", \"people\", \"period\", \"person\", \"picture\", \"piece\", \"place\", \"planet\", \"plant\", \"play\", \"player\", \"point\", \"police\", \"political\", \"politician\", \"popular\", \"population\", \"port\", \"position\", \"possible\", \"power\", \"powerful\", \"present\", \"president\", \"probably\", \"problem\", \"process\", \"produce\", \"product\", \"professional\", \"program\", \"project\", \"prove\", \"provide\", \"province\", \"public\", \"publish\", \"put\", \"quickly\", \"race\", \"radio\", \"railway\", \"range\", \"rare\", \"rather\", \"reach\", \"real\", \"receive\", \"record\", \"refer\", \"reference\", \"region\", \"regular\", \"relative\", \"release\", \"religious\", \"replace\", \"report\", \"represent\", \"research\", \"result\", \"retire\", \"return\", \"right\", \"ring\", \"rise\", \"river\", \"rock\", \"role\", \"roman\", \"room\", \"route\", \"rrb\", \"rule\", \"run\", \"same\", \"say\", \"scale\", \"scene\", \"school\", \"sea\", \"season\", \"second\", \"see\", \"sell\", \"send\", \"separate\", \"series\", \"serve\", \"service\", \"set\", \"several\", \"share\", \"ship\", \"shore\", \"short\", \"should\", \"show\", \"side\", \"similar\", \"sing\", \"singer\", \"single\", \"sister\", \"site\", \"size\", \"small\", \"so\", \"sometimes\", \"son\", \"song\", \"soon\", \"sound\", \"south\", \"southern\", \"southwest\", \"space\", \"spanish\", \"speak\", \"special\", \"specie\", \"sport\", \"stadium\", \"standard\", \"star\", \"start\", \"state\", \"station\", \"still\", \"stone\", \"stop\", \"store\", \"storm\", \"story\", \"string\", \"strong\", \"structure\", \"student\", \"study\", \"style\", \"successful\", \"such\", \"support\", \"surface\", \"symbol\", \"system\", \"table\", \"take\", \"talk\", \"teach\", \"team\", \"television\", \"temperature\", \"term\", \"territory\", \"text\", \"th\", \"th_century\", \"then\", \"theory\", \"there\", \"thing\", \"think\", \"third\", \"time\", \"title\", \"together\", \"top\", \"total\", \"town\", \"tradition\", \"train\", \"tribe\", \"tropical\", \"tropical_storm\", \"try\", \"turn\", \"tv\", \"type\", \"typically\", \"unit\", \"university\", \"use\", \"user\", \"usually\", \"value\", \"version\", \"very\", \"video\", \"village\", \"visit\", \"voice\", \"wall\", \"want\", \"war\", \"water\", \"wave\", \"way\", \"website\", \"week\", \"well\", \"west\", \"western\", \"when\", \"where\", \"white\", \"wide\", \"wife\", \"will\", \"win\", \"wind\", \"winner\", \"woman\", \"word\", \"work\", \"world\", \"would\", \"write\", \"writer\", \"year\", \"young\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 20, 5, 17, 11, 13, 12, 10, 9, 4, 16, 2, 7, 19, 18, 1, 14, 8, 6, 15]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el5441396629833950241290649888\", ldavis_el5441396629833950241290649888_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el5441396629833950241290649888\", ldavis_el5441396629833950241290649888_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el5441396629833950241290649888\", ldavis_el5441396629833950241290649888_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster      Freq\n",
       "topic                                               \n",
       "2     -0.403108 -0.198353       1        1  9.628153\n",
       "19    -0.488739  0.055339       2        1  6.523408\n",
       "4     -0.058945 -0.192844       3        1  5.773782\n",
       "16    -0.142226 -0.433951       4        1  5.552992\n",
       "10     0.093899  0.463928       5        1  5.494105\n",
       "12    -0.147129  0.158742       6        1  5.164802\n",
       "11    -0.381132  0.248841       7        1  5.106026\n",
       "9     -0.319255 -0.343935       8        1  5.095499\n",
       "8      0.056272 -0.471644       9        1  5.018720\n",
       "3      0.327812 -0.366991      10        1  4.939608\n",
       "15     0.167861 -0.294761      11        1  4.899520\n",
       "1      0.257014  0.373236      12        1  4.420342\n",
       "6     -0.309258 -0.019618      13        1  4.345974\n",
       "18     0.107631  0.108894      14        1  4.308096\n",
       "17    -0.239889  0.405081      15        1  4.187696\n",
       "0     -0.059381  0.397232      16        1  4.153211\n",
       "13     0.277642 -0.113010      17        1  3.899681\n",
       "7      0.458245 -0.104093      18        1  3.882072\n",
       "5      0.439154  0.089204      19        1  3.842698\n",
       "14     0.363530  0.238702      20        1  3.763614, topic_info=         Term          Freq         Total Category  logprob  loglift\n",
       "271       nan  24691.000000  24691.000000  Default  30.0000  30.0000\n",
       "343      bear  21237.000000  21237.000000  Default  29.0000  29.0000\n",
       "363      also  21725.000000  21725.000000  Default  28.0000  28.0000\n",
       "224       use  21359.000000  21359.000000  Default  27.0000  27.0000\n",
       "6        make  19497.000000  19497.000000  Default  26.0000  26.0000\n",
       "...       ...           ...           ...      ...      ...      ...\n",
       "560   measure    776.042233    777.144881  Topic20  -4.9345   3.2784\n",
       "3783    merge    736.698647    737.801296  Topic20  -4.9865   3.2783\n",
       "3990     wave    705.518547    706.621195  Topic20  -5.0297   3.2782\n",
       "2795      dry    599.971082    601.073730  Topic20  -5.1918   3.2780\n",
       "5261    cloud    561.493859    562.596507  Topic20  -5.2581   3.2778\n",
       "\n",
       "[630 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "812      18  0.999672     about\n",
       "21       11  0.999513    accord\n",
       "272      13  0.998935       act\n",
       "1280      9  0.999056  activity\n",
       "342      11  0.999679     actor\n",
       "...     ...       ...       ...\n",
       "270       3  0.999804     would\n",
       "121      14  0.999856     write\n",
       "315      15  0.999301    writer\n",
       "33        8  0.999922      year\n",
       "1835      4  0.998988     young\n",
       "\n",
       "[600 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 20, 5, 17, 11, 13, 12, 10, 9, 4, 16, 2, 7, 19, 18, 1, 14, 8, 6, 15])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(Bi_tri_lda_model_saved_model, corpus, id2word, mds=\"mmds\", R=30)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "advanced-devil",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 1), (644, 1), (1634, 1), (2523, 1), (4551, 1)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[400001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "similar-olympus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"They decide to find Shade 's father , Cassiel , and Chinook volunteers to help .\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['original_text'][400001]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "retained-halifax",
   "metadata": {},
   "source": [
    "# Get bag of words for test df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "experienced-chemistry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2386, 1), (21950, 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get back to this if test split returns high accuracy\n",
    "\n",
    "test_sentence = ['This', 'is', 'a', 'test']\n",
    "id2word.doc2bow(test_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fallen-cigarette",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def lemmatize_sentence(sentences, p_o_s=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\\n    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\\n    sentences_out = []\\n    for sentence in tqdm(sentences):\\n        doc = nlp(sentence)\\n        new_sent = []\\n        for token in doc:\\n            if token.pos_ in p_o_s:\\n                new_sent.append(token.lemma_)\\n        final = \" \".join(new_sent)\\n        sentences_out.append(final)\\n    return(sentences_out)\\n\\n\\nlemmatized_sentences = lemmatize_sentence(test_df[\\'original_text\\'])\\nprint (lemmatized_sentences[0][0:50])\\n\\npd.DataFrame(lemmatized_sentences).to_csv(\\'lemmatized_test_sentences.csv\\', index = False)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved to csv\n",
    "def lemmatize_sentence(sentences, p_o_s=[\"NOUN\", \"ADJ\", \"VERB\", \"ADV\"]):\n",
    "    nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "    sentences_out = []\n",
    "    for sentence in tqdm(sentences):\n",
    "        doc = nlp(sentence)\n",
    "        new_sent = []\n",
    "        for token in doc:\n",
    "            if token.pos_ in p_o_s:\n",
    "                new_sent.append(token.lemma_)\n",
    "        final = \" \".join(new_sent)\n",
    "        sentences_out.append(final)\n",
    "    return(sentences_out)\n",
    "\n",
    "\n",
    "lemmatized_sentences = lemmatize_sentence(test_df['original_text'])\n",
    "print (lemmatized_sentences[0][0:50])\n",
    "\n",
    "pd.DataFrame(lemmatized_sentences).to_csv('lemmatized_test_sentences.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "vietnamese-bahrain",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatized_test_sentences = pd.read_csv('lemmatized_test_sentences.csv')\n",
    "lemmatized_test_sentences = lemmatized_test_sentences.fillna('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "organizational-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119092/119092 [00:02<00:00, 50445.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def gen_words(sentences):\n",
    "    final = []\n",
    "    for sentence in tqdm(sentences['0']):\n",
    "        new = gensim.utils.simple_preprocess(sentence, deacc=True)\n",
    "        final.append(new)\n",
    "    return (final)\n",
    "\n",
    "clean_words = gen_words(lemmatized_test_sentences)\n",
    "\n",
    "print(clean_words[1][0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-juice",
   "metadata": {},
   "source": [
    "# Bigrams and trigrams test df\n",
    "Test DF code not used because the accuracy was too low with the train df train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "favorite-annotation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#BIGRAMS AND TRIGRAMS\\nbi_phrases = gensim.models.Phrases(clean_words, min_count=5, threshold=100)\\ntri_phrases = gensim.models.Phrases(bi_phrases[clean_words], threshold=100)\\n\\nbigram = gensim.models.phrases.Phraser(bi_phrases)\\ntrigram = gensim.models.phrases.Phraser(tri_phrases)\\n\\ndef make_bigrams(sentences):\\n    return([bigram[doc] for doc in sentences])\\n\\ndef make_trigrams(sentences):\\n    return ([trigram[bigram[doc]] for doc in sentences])\\n\\ndata_bigrams = make_bigrams(clean_words)\\ndata_bigrams_trigrams = make_trigrams(data_bigrams)\\n\\nprint (data_bigrams_trigrams[0][0:20])'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get back to this if test split returns high accuracy\n",
    "'''#BIGRAMS AND TRIGRAMS\n",
    "bi_phrases = gensim.models.Phrases(clean_words, min_count=5, threshold=100)\n",
    "tri_phrases = gensim.models.Phrases(bi_phrases[clean_words], threshold=100)\n",
    "\n",
    "bigram = gensim.models.phrases.Phraser(bi_phrases)\n",
    "trigram = gensim.models.phrases.Phraser(tri_phrases)\n",
    "\n",
    "def make_bigrams(sentences):\n",
    "    return([bigram[doc] for doc in sentences])\n",
    "\n",
    "def make_trigrams(sentences):\n",
    "    return ([trigram[bigram[doc]] for doc in sentences])\n",
    "\n",
    "data_bigrams = make_bigrams(clean_words)\n",
    "data_bigrams_trigrams = make_trigrams(data_bigrams)\n",
    "\n",
    "print (data_bigrams_trigrams[0][0:20])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "verified-intake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#TF-IDF REMOVAL\\nfrom gensim.models import TfidfModel\\n\\nid2word = corpora.Dictionary(data_bigrams_trigrams)\\n\\nsentences = data_bigrams_trigrams\\n\\ncorpus = [id2word.doc2bow(sentence) for sentence in sentences]\\n# print (corpus[0][0:20])\\n\\ntfidf = TfidfModel(corpus, id2word=id2word)\\n\\nlow_value = 0.03\\nwords  = []\\nwords_missing_in_tfidf = []\\nfor i in range(0, len(corpus)):\\n    bow = corpus[i]\\n    low_val_words = []\\n    tfidf_ids = [id for id, value in tfidf[bow]]\\n    bow_ids = [id for id, value in bow]\\n    low_val_words = [id for id, value in tfidf[bow] if value < low_value]\\n    drops = low_val_words+words_missing_in_tfidf\\n    for item in drops:\\n        words.append(id2word[item])\\n    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\\n\\n    new_bow = [b for b in bow if b[0] not in low_val_words and b[0] not in words_missing_in_tfidf]\\n    corpus[i] = new_bow'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get back to this if test split returns high accuracy\n",
    "'''#TF-IDF REMOVAL\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "id2word = corpora.Dictionary(data_bigrams_trigrams)\n",
    "\n",
    "sentences = data_bigrams_trigrams\n",
    "\n",
    "corpus = [id2word.doc2bow(sentence) for sentence in sentences]\n",
    "# print (corpus[0][0:20])\n",
    "\n",
    "tfidf = TfidfModel(corpus, id2word=id2word)\n",
    "\n",
    "low_value = 0.03\n",
    "words  = []\n",
    "words_missing_in_tfidf = []\n",
    "for i in range(0, len(corpus)):\n",
    "    bow = corpus[i]\n",
    "    low_val_words = []\n",
    "    tfidf_ids = [id for id, value in tfidf[bow]]\n",
    "    bow_ids = [id for id, value in bow]\n",
    "    low_val_words = [id for id, value in tfidf[bow] if value < low_value]\n",
    "    drops = low_val_words+words_missing_in_tfidf\n",
    "    for item in drops:\n",
    "        words.append(id2word[item])\n",
    "    words_missing_in_tfidf = [id for id in bow_ids if id not in tfidf_ids]\n",
    "\n",
    "    new_bow = [b for b in bow if b[0] not in low_val_words and b[0] not in words_missing_in_tfidf]\n",
    "    corpus[i] = new_bow'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "possible-wheel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['feb']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['nan']\n",
      "['direct', 'video', 'sequel', 'film']\n",
      "['fact', 'excommunicate', 'leave', 'second', 'time', 'result', 'victory', 'mark', 'end']\n",
      "['tv', 'series', 'base', 'famous', 'video', 'game', 'character']\n",
      "['nan']\n",
      "['shall', 'issue', 'probable', 'cause', 'support', 'affirmation', 'particularly', 'describe', 'place', 'search', 'person', 'thing', 'seize']\n",
      "['represent', 'occasion', 'require', 'prompt', 'attendance', 'spot', 'keep', 'study', 'ignorance', 'part', 'concerted', 'national', 'rising', 'still', 'look', 'submissive', 'vassal']\n",
      "['represent', 'occasion', 'require', 'prompt', 'attendance', 'spot', 'keep', 'study', 'ignorance', 'part', 'concerted', 'national', 'rising', 'still', 'look', 'submissive', 'vassal']\n",
      "['home']\n",
      "['life', 'alternative', 'rock', 'song', 'canadian', 'alternative', 'rock', 'band', 'second', 'single', 'fourth', 'studio', 'album', 'release']\n",
      "['somewhere', 'out', 'there', 'alternative', 'rock', 'song', 'canadian', 'alternative', 'rock', 'band', 'first', 'single', 'fifth', 'studio', 'album', 'release']\n",
      "['song', 'feature', 'singer']\n",
      "['sometimes', 'nickname', 'death', 'year', 'later']\n",
      "['chinese', 'general']\n",
      "['nan']\n",
      "['season', 'total', 'episode']\n",
      "['german', 'composer', 'pianist']\n",
      "['automated', 'number', 'plate', 'recognition', 'system', 'traffic', 'environment', 'culminate', 'generally', 'refer', 'know', 're', 'steel']\n",
      "['automated', 'number', 'plate', 'recognition', 'system', 'traffic', 'environment', 'culminate', 'generally', 'refer', 'know', 're', 'steel']\n",
      "['nan']\n",
      "['fast', 'guitarist', 'time']\n",
      "['thing', 'single', 'release', 'album', 'music', 'video', 'thing', 'release']\n",
      "['thing', 'also', 'success']\n",
      "['expansion', 'pack']\n",
      "['current', 'list', 'liberal', 'democracy', 'include', 'serve', 'head', 'government', 'serve', 'legislative', 'body']\n",
      "['day', 'life', 'song', 'rock', 'group', 'final', 'track', 'group', 'album']\n",
      "['day', 'life', 'song', 'rock', 'group', 'final', 'track', 'group', 'album']\n",
      "['day', 'life', 'song', 'rock', 'group', 'final', 'track', 'group', 'album']\n",
      "['day', 'life', 'key', 'major', 'explain', 'true', 'center', 'gravity', 'parallel', 'minor', 'major', 'key', 'verse', 'bridge', 'major']\n",
      "['game', 'form', 'art', 'participant', 'term', 'player', 'make', 'decision', 'order', 'manage', 'resource', 'game', 'token', 'pursuit', 'goal']\n",
      "['game', 'form', 'play', 'goal', 'structure']\n",
      "['history', 'publish']\n",
      "['kamikaze', 'surprise', 'attack', 'accord', 'ancient', 'war', 'tactic']\n",
      "['mile', 'away']\n",
      "['new', 'fossil', 'porpoise', 'early']\n",
      "['look', 'history']\n",
      "['place']\n",
      "['well', 'regulated', 'necessary', 'security', 'free', 'right', 'people', 'keep', 'bear', 'arm', 'shall', 'infringe']\n",
      "['abortion', 'no', 'long', 'dangerous', 'procedure']\n",
      "['about']\n",
      "['about', 'girl']\n",
      "['acronym', 'access', 'word', 'create', 'frst', 'letter', 'word', 'series', 'word']\n",
      "['acronym']\n",
      "['song', 'group']\n",
      "['song', 'rock', 'group']\n",
      "['nan']\n",
      "['nan']\n",
      "['add', 'back', 'when', 'find', 'reference', 'manner', 'eat', 'spaghetti', 'vary', 'accord', 'local', 'custom', 'traditionally', 'eat', 'twist', 'spaghetti', 'fork']\n",
      "['addict']\n",
      "['out', 'late', 'year', 'sometimes', 'setting', 'must', 'precise', 'where', 'would', 'too', 'close', 'would', 'separate', 'line', 'too', 'much', 'provide', 'even', 'balance', 'particular']\n",
      "['late', 'year', 'sometimes', 'setting', 'must', 'precise', 'where', 'would', 'too', 'close', 'would', 'separate', 'line', 'too', 'much', 'provide', 'even', 'balance', 'particular', 'line']\n",
      "['start', 'part', 'project', 'title', 'hence', 'co', 'writing', 'credit']\n",
      "['know', 'song', 'american', 'rock', 'band', 'release', 'debut', 'album', 'know', 'fall']\n",
      "['base', 'belong', 'often', 'shorten', 'aybabtu', 'simply', 'broken', 'english', 'phrase', 'become', 'internet', 'phenomenon', 'meme']\n",
      "['base', 'belong', 'often', 'shorten', 'aybabtu', 'simply', 'broken', 'english', 'phrase', 'begin', 'internet', 'phenomenon', 'use', 'animation']\n",
      "['song', 'mexican', 'pop', 'singer']\n",
      "['recent', 'measurement', 'temperature']\n",
      "['foot', 'ancient', 'time', 'short', 'poem']\n",
      "['foot', 'ancient', 'time', 'short', 'poem', 'preface', 'epic']\n",
      "['construct', 'sky', 'space', 'might', 'steadily', 'expand']\n",
      "['construct', 'sky', 'space', 'might', 'steadily', 'expand']\n",
      "['grow', 'annoy']\n",
      "['grow', 'annoy', 'such', 'insolence']\n",
      "['russian', 'iconographer', 'lrb', 'bear']\n",
      "['angel']\n",
      "['one', 'bite', 'try', 'suicide', 'release']\n",
      "['nan']\n",
      "['antix']\n",
      "['like', 'instrumental', 'song']\n",
      "['archaeologist', 'dig', 'peace', 'camp', 'most', 'importance', 'learn', 'prehistoric', 'society', 'when', 'write', 'record', 'historian', 'study', 'make', 'total', 'human', 'history', 'advent', 'literacy']\n",
      "['dance']\n",
      "['argument', 'predict', 'productivity', 'should', 'increase', 'patent', 'firm']\n",
      "['arm', 'publish', 'advantage', 'extended', 'range', 'demonstrate', 'where', 'rifle', 'musket', 'inflict', 'heavy', 'casualty', 'indian', 'warrior', 'could', 'smooth', 'bore', 'musket', 'range']\n",
      "['arm', 'publish', 'advantage', 'long', 'distance', 'show', 'where', 'rifle', 'musket', 'kill', 'indian', 'warrior', 'could', 'close', 'enough', 'smooth', 'bore', 'musket']\n",
      "['least', 'as', 'much', 'attack', 'theological', 'point', 'view', 'note', 'book', 'laud', 'take', 'pulpit', 'most', 'interesting', 'satisfying', 'several', 'different', 'faith']\n",
      "['least', 'as', 'much', 'attack', 'theological', 'point', 'view', 'say', 'book', 'laud', 'praise', 'take', 'pulpit', 'most', 'interesting', 'satisfying', 'several', 'different', 'faith']\n",
      "['attitude']\n",
      "['state', 'name', 'macedonian', 'language', 'name', 'identical', 'spell', 'cyrillic', 'alphabet']\n",
      "['nan']\n",
      "['song', 'english', 'rock', 'band', 'write']\n",
      "['baptism']\n",
      "['audience', 'rise', 'again', 'retrieve']\n",
      "['nan']\n",
      "['hungarian', 'name']\n",
      "['brother']\n",
      "['co', 'write', 'label']\n",
      "['grunge', 'song', 'american', 'grunge', 'band', 'fourth', 'studio', 'album', 'release']\n",
      "['song', 'american', 'rock', 'band', 'write', 'frontman', 'release', 'third', 'single', 'band', 'fourth', 'studio', 'album']\n",
      "['bleed']\n",
      "['blood', 'hide', 'track', 'start']\n",
      "['second', 'final', 'episode', 'second', 'season']\n",
      "['second', 'last', 'episode', 'second', 'season']\n",
      "['nan']\n",
      "['most', 'basic', 'single', 'version', 'blue', 'scale', 'commonly', 'use', 'change', 'chord', 'bar', 'blue', 'progression']\n",
      "['song', 'british', 'rock', 'band']\n",
      "['book', 'lyric', 'music']\n",
      "['book', 'music', 'lyric']\n",
      "['bootylicious', 'song', 'group', 'child']\n",
      "['bore', 'redirect', 'here']\n",
      "['redirect', 'here']\n",
      "['nan']\n",
      "['song']\n",
      "['brain', 'damage', 'brain', 'injury', 'destruction', 'degeneration', 'brain', 'cell']\n",
      "['brother', 'song', 'release', 'first', 'single', 'follow', 'release', 'year', 'early']\n",
      "['brother', 'song', 'release', 'first', 'single', 'follow', 'release', 'year', 'early']\n",
      "['sentence', 'use', 'correct', 'grammar']\n",
      "['nan']\n",
      "['build', 'then', 'fifth', 'last', 'official', 'single', 'write', 'panic', 'album', 'can', 'sweat', 'include', 'radio', 'only', 'single', 'only', 'coverage']\n",
      "['reign', 'emperor']\n",
      "['burn', 'fourth', 'single', 'fifth', 'single', 'come', 'release', 'canadian', 'post', 'grunge', 'band', 'sixth', 'studio', 'album']\n",
      "['song', 'trip', 'hop', 'band']\n",
      "['song', 'trip', 'hop', 'collective', 'fourth', 'full', 'length', 'album', 'th']\n",
      "['catch', 'african', 'fever', 'race', 'territory']\n",
      "['ca', 'stop', 'thing', 'start', 'song']\n",
      "['now', 'use', 'people', 'part', 'refer', 'modern', 'football']\n",
      "['ndash', 'ndash', 'julian', 'calendar']\n",
      "['carry', 'song']\n",
      "['chess', 'icon', 'body', 'exhume', 'paternity', 'case', 'report']\n",
      "['single', 'hip', 'hop', 'duo', 'second', 'studio', 'album']\n",
      "['child', 'introduce', 'launch', 'dedicated', 'block', 'program', 'presentation', 'aim', 'young', 'viewer', 'previously', 'broadcast', 'child', 'programming', 'use', 'regular', 'duty', 'announcer']\n",
      "['go']\n",
      "['chinese', 'shake', 'roll', 'music', 'chinese', 'rock', 'roll', 'music', 'genre', 'music', 'lifestyle']\n",
      "['chinese', 'shake', 'roll', 'music', 'chinese', 'rock', 'roll', 'music', 'genre', 'music', 'lifestyle']\n",
      "['church', 'leader', 'sue', 'sex', 'abuse', 'case']\n",
      "['clad']\n",
      "['come', 'back']\n",
      "['come', 'back']\n",
      "['come', 'back']\n",
      "['come']\n",
      "['come', 'together', 'song', 'write', 'mostly', 'credit']\n",
      "['come', 'together', 'song', 'write', 'primarily', 'credit']\n",
      "['song', 'mexican', 'american', 'singer', 'third', 'studio', 'album']\n",
      "['song', 'mexican', 'american', 'singer', 'third', 'studio', 'album']\n",
      "['song', 'american', 'band', 'self', 'title', 'debut', 'album']\n",
      "['call', 'sail', 'away', 'never', 'come', 'soon', 'save', 'record']\n",
      "['crazy']\n",
      "['crush']\n",
      "['nan']\n",
      "['nan']\n",
      "['dare', 'stupid', 'original', 'song']\n",
      "['dare', 'stupid', 'original', 'song']\n",
      "['man', 'kill', 'spark', 'rrb']\n",
      "['day']\n",
      "['instrumental']\n",
      "['song', 'pen', 'favorite', 'housecat', 'female', 'tortoiseshell', 'cat', 'name']\n",
      "['dig', 'song', 'originally', 'release', 'album', 'let']\n",
      "['dig', 'song']\n",
      "['song', 'american', 'rapper', 'nelly', 'duet', 'singer']\n",
      "['song', 'american', 'rapper', 'nelly', 'duet', 'singer']\n",
      "['remix', 'edit']\n",
      "['remix', 'edit']\n",
      "['in', 'however', 'obscurity', 'may', 'restful', 'previous', 'life', 'spotlight', 'still', 'very', 'much', 'dark', 'vocation']\n",
      "['dirty']\n",
      "['disaster']\n",
      "['disaster']\n",
      "['disenchant']\n",
      "['nan']\n",
      "['download', 'song']\n",
      "['download', 'song', 'first', 'single', 'th', 'studio', 'album']\n",
      "['stop', 'up', 'tempo', 'dance', 'groove', 'stop', 'incorporate', 'electropop', 'house', 'music', 'use', 'dark', 'sound', 'vocal', 'effect', 'use', 'song', 'vocal']\n",
      "['doctor', 'tell', 'take', 'rest', 'year', 'off', 'way', 'say', 'long', 'wait', 'hard', 'go']\n",
      "['rosarium', 'now']\n",
      "['rosarium', 'now']\n",
      "['panic']\n",
      "['may', 'offensive', 'merely', 'humorously', 'deprecate', 'cacophemism', 'usually', 'deliberately', 'offensive']\n",
      "['malphemism', 'may', 'offensive', 'merely', 'humorously', 'deprecate', 'cacophemism', 'usually', 'deliberately', 'offensive']\n",
      "['combine', 'brand', 'lyrical', 'imagery', 'string', 'octet', 'conventional', 'string', 'quartet', 'double', 'arrange', 'direction']\n",
      "['nan']\n",
      "[]\n",
      "['emergency', 'song', 'american', 'rock', 'band']\n",
      "['emotion', 'record', 'group', 'child', 'produce', 'arrange']\n",
      "['emotion', 'remake', 'group', 'produce', 'arrange']\n",
      "['emotion', 'remake', 'group', 'produce', 'arrange']\n",
      "['song']\n",
      "['song', 'perform', 'american', 'rapper', 'hip', 'hop', 'artist', 'feature', 'vocal', 'soul', 'singer']\n",
      "['nan']\n",
      "['nan']\n",
      "['equal', 'just']\n",
      "['essay', 'vendian']\n",
      "['nan']\n",
      "['nan']\n",
      "['ever', 'want']\n",
      "['evil', 'mind', 'name', 'popular', 'music', 'song', 'originally', 'make', 'famous', 'star']\n",
      "['evolution', 'consist', 'mainly', 'change', 'frequency', 'allele', 'generation', 'propose', 'rather', 'later']\n",
      "['extension']\n",
      "['extension']\n",
      "['extreme', 'body', 'modification']\n",
      "['faith', 'many', 'success', 'faith', 'more', 'score']\n",
      "['faith', 'school', 'mainstream', 'church', 'continue', 'wrestle', 'homosexuality', 'religious', 'college', 'take', 'increasingly', 'welcoming', 'attitude', 'gay', 'student']\n",
      "['faith', 'school', 'mainstream', 'church', 'continue', 'wrestle', 'homosexuality', 'religious', 'college', 'take', 'increasingly', 'welcoming', 'attitude', 'gay', 'student', 'emancipatory']\n",
      "['faker', 'redirect', 'here']\n",
      "['nan']\n",
      "['now', 'more', 'common', 'consider', 'well', 'term']\n",
      "['well', 'term']\n",
      "['fix', 'song', 'mainly', 'write', 'lrb', 'credit', 'perform', 'album']\n",
      "['fix', 'song', 'mainly', 'write', 'lrb', 'credit', 'perform', 'album']\n",
      "['fix', 'song', 'mainly', 'write', 'lrb', 'credit', 'perform', 'album']\n",
      "['flannery', 'take', 'top', 'gong']\n",
      "['flexibility', 'refer', 'agility', 'possibility', 'great', 'flexibility', 'assist', 'play', 'music', 'fast', 'passage', 'large', 'interval']\n",
      "['flight', 'cost', 'long', 'sexually', 'select', 'tail', 'hummingbird']\n",
      "['fly', 'heart']\n",
      "['fly', 'kari']\n",
      "['song', 'american', 'heavy', 'metal', 'band', 'release', 'third', 'final', 'single', 'second', 'album', 'ride', 'lightning']\n",
      "['debut', 'mainstream', 'single', 'american', 'recording', 'artist', 'season', 'runner']\n",
      "['nan']\n",
      "['nan']\n",
      "['flemish', 'composer', 'term', 'use', 'composer', 'come']\n",
      "['scientist', 'create', 'monster']\n",
      "['collect', 'page', 'dispute', 'conclusion', 'note', 'already', 'fourth', 'fifth', 'industrial', 'economy', 'russian', 'industrial', 'advance', 'could', 'achieve', 'famine', 'terror']\n",
      "['enable', 'student', 'well', 'training', 'give', 'speech']\n",
      "['friend', 'first', 'single', 'album', 'release']\n",
      "['friendly', 'fuel', 'train']\n",
      "['friend', 'let', 'friend']\n",
      "['friendship', 'band', 'very', 'popular', 'part']\n",
      "['show', 'love']\n",
      "['nan']\n",
      "['here']\n",
      "['get', 'well', 'song', 'write', 'base', 'original', 'idea']\n",
      "['get', 'well', 'song', 'write', 'mainly', 'lyrical', 'contribution', 'credit']\n",
      "['nan']\n",
      "['fourth', 'single', 'post', 'grunge', 'band']\n",
      "['fourth', 'single', 'grunge', 'alternative', 'rock', 'band', 'debut', 'album']\n",
      "['national', 'anthem', 'together', 'save']\n",
      "['national', 'anthem']\n",
      "['national', 'anthem', 'other', 'national', 'anthem', 'sung', 'very', 'often']\n",
      "['ball', 'randomly', 'draw', 'machine', 'ball', 'add']\n",
      "['good', 'hand', 'bad', 'hand', 'account', 'keep', 'account', 'clean', 'use', 'engage', 'disruption']\n",
      "['good', 'hand', 'bad', 'hand', 'account']\n",
      "['bosnian', 'herzegovinian', 'entry', 'perform', 'title']\n",
      "['watch']\n",
      "['watch']\n",
      "['graduation', 'forever']\n",
      "['graduation', 'forever']\n",
      "['th', 'game', 'series']\n",
      "['great', 'ape', 'common', 'name', 'rather', 'taxonomic', 'label', 'difference', 'usage']\n",
      "['nan']\n",
      "['gump', 'song']\n",
      "['gump', 'song', 'parody', 'president']\n",
      "['gump', 'song', 'american', 'musical', 'parodist']\n",
      "['hop', 'song', 'band', 'first', 'single', 'fourth', 'studio', 'album', 'release']\n",
      "['first', 'single', 'american', 'hip', 'hop', 'duo', 'fourth', 'studio', 'album']\n",
      "['wedding']\n",
      "['hard', 'breathe', 'song', 'american', 'rock', 'band']\n",
      "['hard', 'breathe', 'first', 'single', 'first', 'track', 'first', 'album']\n",
      "['hate', 'really', 'like']\n",
      "['hate', 'really', 'like']\n",
      "['hate', 'really', 'like']\n",
      "['hear']\n",
      "['hear', 'co', 'write']\n",
      "['heart', 'song', 'american', 'grunge', 'band', 'write', 'vocalist', 'guitarist']\n",
      "['heart', 'song', 'american', 'grunge', 'band', 'write', 'lead', 'singer', 'guitarist']\n",
      "['nan']\n",
      "['astronomer']\n",
      "['astronomer']\n",
      "['there']\n",
      "['there']\n",
      "['there']\n",
      "['there', 'bonus']\n",
      "['nan']\n",
      "['formally']\n",
      "['historically', 'rival', 'tribe', 'control', 'smuggling', 'route', 'major', 'mountain', 'pass', 'connect', 'indian', 'subcontinent', 'other', 'more', 'famous']\n",
      "['history']\n",
      "['nan']\n",
      "['hold', 'touch', 'think', 'when', 'apart']\n",
      "['home']\n",
      "['fragment', 'state', 'attribute', 'god', 'sort', 'thing', 'matter', 'reproach', 'censure', 'man', 'theft', 'adultery', 'mutual', 'deception']\n",
      "['tenth', 'episode', 'first', 'season', 'first', 'start']\n",
      "['tenth', 'episode', 'first', 'season', 'originally', 'air']\n"
     ]
    }
   ],
   "source": [
    "for x in range(300):\n",
    "    print(clean_words[x][0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fitted-macro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'id2word = corpora.Dictionary(clean_words)\\n\\ncorpus = []\\nfor sentence in tqdm(clean_words):\\n    new = id2word.doc2bow(sentence)\\n    corpus.append(new)\\n\\nprint (corpus[0][0:20])\\n\\nword = id2word[[0][:1][0]]\\nprint(word)'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#don't use seperately for test set\n",
    "'''id2word = corpora.Dictionary(clean_words)\n",
    "\n",
    "corpus = []\n",
    "for sentence in tqdm(clean_words):\n",
    "    new = id2word.doc2bow(sentence)\n",
    "    corpus.append(new)\n",
    "\n",
    "print (corpus[0][0:20])\n",
    "\n",
    "word = id2word[[0][:1][0]]\n",
    "print(word)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "amended-sympathy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['song',\n",
       " 'perform',\n",
       " 'american',\n",
       " 'rapper',\n",
       " 'hip',\n",
       " 'hop',\n",
       " 'artist',\n",
       " 'feature',\n",
       " 'vocal',\n",
       " 'soul',\n",
       " 'singer']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_words[206]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "functional-writing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06958477"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_bow_test = id2word.doc2bow(clean_words[30])\n",
    "doc_lda_test = Bi_tri_lda_model_saved_model[doc_bow_test]\n",
    "doc_lda_test[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "generic-thirty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.032189965), (1, 0.03154046), (2, 0.068925306), (3, 0.053861927), (4, 0.05969587), (5, 0.027253583), (6, 0.03106805), (7, 0.027563699), (8, 0.09242711), (9, 0.036161833), (10, 0.04065343), (11, 0.036830444), (12, 0.056090288), (13, 0.027661758), (14, 0.026802726), (15, 0.053541884), (16, 0.05924226), (17, 0.16203508), (18, 0.030801607), (19, 0.04565275)]\n",
      "[(0, 0.03711057), (1, 0.05819915), (2, 0.07946133), (3, 0.06209534), (4, 0.046983704), (5, 0.031419605), (6, 0.057654522), (7, 0.14096394), (8, 0.04104357), (9, 0.041689582), (10, 0.046867773), (11, 0.042460397), (12, 0.042826965), (13, 0.031890176), (14, 0.03089983), (15, 0.03988901), (16, 0.046460755), (17, 0.033942446), (18, 0.03550999), (19, 0.0526313)]\n",
      "[(0, 0.033562277), (1, 0.07411271), (2, 0.07330947), (3, 0.056195088), (4, 0.0483704), (5, 0.028458066), (6, 0.03243645), (7, 0.02879704), (8, 0.037039686), (9, 0.058377292), (10, 0.04281009), (11, 0.038880367), (12, 0.039152898), (13, 0.028890517), (14, 0.02803424), (15, 0.17508471), (16, 0.04189112), (17, 0.050653633), (18, 0.03212481), (19, 0.051819168)]\n",
      "[(0, 0.02859359), (1, 0.04567049), (2, 0.061360642), (3, 0.041464653), (4, 0.038017403), (5, 0.058982126), (6, 0.02800928), (7, 0.024973663), (8, 0.051015962), (9, 0.031972624), (10, 0.05274843), (11, 0.06652166), (12, 0.03492384), (13, 0.23221354), (14, 0.024088362), (15, 0.048112772), (16, 0.035455074), (17, 0.027247945), (18, 0.027882919), (19, 0.040745035)]\n",
      "[(0, 0.036367558), (1, 0.03561657), (2, 0.07707068), (3, 0.039369944), (4, 0.04586653), (5, 0.030845158), (6, 0.035132308), (7, 0.031209081), (8, 0.04012595), (9, 0.0837759), (10, 0.088665776), (11, 0.041521635), (12, 0.041863933), (13, 0.03130034), (14, 0.030372413), (15, 0.039017152), (16, 0.15250431), (17, 0.033276077), (18, 0.034803234), (19, 0.05129548)]\n",
      "[(0, 0.037110575), (1, 0.036361787), (2, 0.079461336), (3, 0.040257983), (4, 0.046983708), (5, 0.03141961), (6, 0.035817157), (7, 0.03177713), (8, 0.041043572), (9, 0.17271379), (10, 0.046867777), (11, 0.0424604), (12, 0.064664334), (13, 0.031890176), (14, 0.030899834), (15, 0.039889015), (16, 0.068298124), (17, 0.03394245), (18, 0.03550999), (19, 0.052631304)]\n",
      "[(0, 0.037343524), (1, 0.0377216), (2, 0.08023756), (3, 0.04048761), (4, 0.20111315), (5, 0.03163125), (6, 0.03605109), (7, 0.031994745), (8, 0.04127387), (9, 0.0419299), (10, 0.047119603), (11, 0.04270204), (12, 0.043067086), (13, 0.032103144), (14, 0.031118466), (15, 0.04015925), (16, 0.04670286), (17, 0.048569616), (18, 0.0357335), (19, 0.052940097)]\n",
      "[(0, 0.03975585), (1, 0.06251951), (2, 0.08421349), (3, 0.043034617), (4, 0.050128017), (5, 0.03372165), (6, 0.038409818), (7, 0.03412187), (8, 0.043858007), (9, 0.044573322), (10, 0.050036684), (11, 0.045387812), (12, 0.04575747), (13, 0.034220774), (14, 0.056968346), (15, 0.113217615), (16, 0.049569193), (17, 0.036377747), (18, 0.038073935), (19, 0.056054313)]\n",
      "[(0, 0.038978145), (1, 0.038119055), (2, 0.08006433), (3, 0.06522966), (4, 0.04861967), (5, 0.03337515), (6, 0.03778845), (7, 0.03408848), (8, 0.04267617), (9, 0.043436356), (10, 0.04854876), (11, 0.16069485), (12, 0.044498853), (13, 0.03373722), (14, 0.033015464), (15, 0.041559193), (16, 0.04810033), (17, 0.036054578), (18, 0.037322763), (19, 0.054092497)]\n",
      "[(0, 0.04066241), (1, 0.03984196), (2, 0.15884879), (3, 0.044111058), (4, 0.051480502), (5, 0.034426767), (6, 0.039245207), (7, 0.034818508), (8, 0.04497184), (9, 0.045679685), (10, 0.07528089), (11, 0.04652427), (12, 0.046925925), (13, 0.034942377), (14, 0.033857245), (15, 0.04370678), (16, 0.0509075), (17, 0.03719107), (18, 0.038908638), (19, 0.057668626)]\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    print(Bi_tri_lda_model_saved_model.get_document_topics(corpus, per_word_topics=True)[x][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-duplicate",
   "metadata": {},
   "source": [
    "# Text vector for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "annual-consequence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "416768"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "australian-satellite",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"topic_count = 20\\n\\nfor y in range(topic_count):\\n    train_df['sentence_vectors_'+str(y)] = .00001\\n\\nfor x in tqdm(range(100000)):\\n    for y in range(topic_count):\\n        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\\n        \\ntrain_df.to_csv('train_df_bi_tri_vectors_1.csv', index = False)\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count = 20\n",
    "\n",
    "for y in range(topic_count):\n",
    "    train_df['sentence_vectors_'+str(y)] = .00001\n",
    "\n",
    "for x in tqdm(range(100000)):\n",
    "    for y in range(topic_count):\n",
    "        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\n",
    "        \n",
    "train_df.to_csv('train_df_bi_tri_vectors_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "outstanding-nursery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"topic_count = 20\\n\\nfor y in range(topic_count):\\n    train_df['sentence_vectors_'+str(y)] = .00001\\n\\nfor x in tqdm(range(100000,200000)):\\n    for y in range(topic_count):\\n        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\\n        \\ntrain_df.to_csv('train_df_bi_tri_vectors_2.csv', index = False)\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count = 20\n",
    "\n",
    "for y in range(topic_count):\n",
    "    train_df['sentence_vectors_'+str(y)] = .00001\n",
    "\n",
    "for x in tqdm(range(100000,200000)):\n",
    "    for y in range(topic_count):\n",
    "        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\n",
    "        \n",
    "train_df.to_csv('train_df_bi_tri_vectors_2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "operational-model",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"topic_count = 20\\n\\nfor y in range(topic_count):\\n    train_df['sentence_vectors_'+str(y)] = .00001\\n\\nfor x in tqdm(range(200000,300000)):\\n    for y in range(topic_count):\\n        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\\n        \\ntrain_df.to_csv('train_df_bi_tri_vectors_3.csv', index = False)\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count = 20\n",
    "\n",
    "for y in range(topic_count):\n",
    "    train_df['sentence_vectors_'+str(y)] = .00001\n",
    "\n",
    "for x in tqdm(range(200000,300000)):\n",
    "    for y in range(topic_count):\n",
    "        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\n",
    "        \n",
    "train_df.to_csv('train_df_bi_tri_vectors_3.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "seventh-porter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"topic_count = 20\\n\\nfor y in range(topic_count):\\n    train_df['sentence_vectors_'+str(y)] = .00001\\n\\nfor x in tqdm(range(300000,len(train_df))):\\n    for y in range(topic_count):\\n        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\\n        \\ntrain_df.to_csv('train_df_bi_tri_vectors_4.csv', index = False)\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_count = 20\n",
    "\n",
    "for y in range(topic_count):\n",
    "    train_df['sentence_vectors_'+str(y)] = .00001\n",
    "\n",
    "for x in tqdm(range(300000,len(train_df))):\n",
    "    for y in range(topic_count):\n",
    "        train_df['sentence_vectors_'+str(y)][x] = Bi_tri_lda_model_saved_model.get_document_topics(corpus)[x][y][1]\n",
    "        \n",
    "train_df.to_csv('train_df_bi_tri_vectors_4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "forced-playlist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_vectors_0</th>\n",
       "      <th>sentence_vectors_1</th>\n",
       "      <th>sentence_vectors_2</th>\n",
       "      <th>sentence_vectors_3</th>\n",
       "      <th>sentence_vectors_4</th>\n",
       "      <th>sentence_vectors_5</th>\n",
       "      <th>sentence_vectors_6</th>\n",
       "      <th>sentence_vectors_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_vectors_10</th>\n",
       "      <th>sentence_vectors_11</th>\n",
       "      <th>sentence_vectors_12</th>\n",
       "      <th>sentence_vectors_13</th>\n",
       "      <th>sentence_vectors_14</th>\n",
       "      <th>sentence_vectors_15</th>\n",
       "      <th>sentence_vectors_16</th>\n",
       "      <th>sentence_vectors_17</th>\n",
       "      <th>sentence_vectors_18</th>\n",
       "      <th>sentence_vectors_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>There is manuscript evidence that Austen conti...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.032190</td>\n",
       "      <td>0.031540</td>\n",
       "      <td>0.068925</td>\n",
       "      <td>0.053862</td>\n",
       "      <td>0.059696</td>\n",
       "      <td>0.027254</td>\n",
       "      <td>0.031068</td>\n",
       "      <td>0.027564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040653</td>\n",
       "      <td>0.036830</td>\n",
       "      <td>0.056090</td>\n",
       "      <td>0.027662</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.053542</td>\n",
       "      <td>0.059242</td>\n",
       "      <td>0.162035</td>\n",
       "      <td>0.030802</td>\n",
       "      <td>0.045653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a remarkable comparative analysis , Mandaea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.037111</td>\n",
       "      <td>0.058199</td>\n",
       "      <td>0.079461</td>\n",
       "      <td>0.062095</td>\n",
       "      <td>0.046984</td>\n",
       "      <td>0.031420</td>\n",
       "      <td>0.057655</td>\n",
       "      <td>0.140964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046868</td>\n",
       "      <td>0.042460</td>\n",
       "      <td>0.042827</td>\n",
       "      <td>0.031890</td>\n",
       "      <td>0.030900</td>\n",
       "      <td>0.039889</td>\n",
       "      <td>0.046461</td>\n",
       "      <td>0.033942</td>\n",
       "      <td>0.035510</td>\n",
       "      <td>0.052631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Before Persephone was released to Hermes , who...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033562</td>\n",
       "      <td>0.074113</td>\n",
       "      <td>0.073309</td>\n",
       "      <td>0.056195</td>\n",
       "      <td>0.048367</td>\n",
       "      <td>0.028458</td>\n",
       "      <td>0.032436</td>\n",
       "      <td>0.028797</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042810</td>\n",
       "      <td>0.038881</td>\n",
       "      <td>0.039153</td>\n",
       "      <td>0.028891</td>\n",
       "      <td>0.028034</td>\n",
       "      <td>0.175085</td>\n",
       "      <td>0.041891</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>0.032125</td>\n",
       "      <td>0.051821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cogeneration plants are commonly found in dist...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.028594</td>\n",
       "      <td>0.045670</td>\n",
       "      <td>0.061359</td>\n",
       "      <td>0.041469</td>\n",
       "      <td>0.038020</td>\n",
       "      <td>0.058981</td>\n",
       "      <td>0.028009</td>\n",
       "      <td>0.024975</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052748</td>\n",
       "      <td>0.066521</td>\n",
       "      <td>0.034926</td>\n",
       "      <td>0.232206</td>\n",
       "      <td>0.024089</td>\n",
       "      <td>0.048113</td>\n",
       "      <td>0.035455</td>\n",
       "      <td>0.027248</td>\n",
       "      <td>0.027884</td>\n",
       "      <td>0.040745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Geneva -LRB- , ; , ; , ; ; -RRB- is the second...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.036368</td>\n",
       "      <td>0.035617</td>\n",
       "      <td>0.077071</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>0.045866</td>\n",
       "      <td>0.030845</td>\n",
       "      <td>0.035132</td>\n",
       "      <td>0.031208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088666</td>\n",
       "      <td>0.041521</td>\n",
       "      <td>0.041864</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.030373</td>\n",
       "      <td>0.039017</td>\n",
       "      <td>0.152504</td>\n",
       "      <td>0.033276</td>\n",
       "      <td>0.034803</td>\n",
       "      <td>0.051296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416763</th>\n",
       "      <td>A Duke Nukem 3D version has been sold for Xbox...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.065333</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.060186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.069292</td>\n",
       "      <td>0.052155</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.059082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416764</th>\n",
       "      <td>However , it is becoming replaced as a method ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037939</td>\n",
       "      <td>0.037286</td>\n",
       "      <td>0.092645</td>\n",
       "      <td>0.063482</td>\n",
       "      <td>0.048975</td>\n",
       "      <td>0.054446</td>\n",
       "      <td>0.059083</td>\n",
       "      <td>0.082415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047916</td>\n",
       "      <td>0.043409</td>\n",
       "      <td>0.043783</td>\n",
       "      <td>0.032602</td>\n",
       "      <td>0.031590</td>\n",
       "      <td>0.040780</td>\n",
       "      <td>0.073071</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.036303</td>\n",
       "      <td>0.054106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416765</th>\n",
       "      <td>There are hand gestures in both Hindu and Budd...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.042634</td>\n",
       "      <td>0.041708</td>\n",
       "      <td>0.090511</td>\n",
       "      <td>0.046131</td>\n",
       "      <td>0.053824</td>\n",
       "      <td>0.036085</td>\n",
       "      <td>0.041194</td>\n",
       "      <td>0.063919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.053751</td>\n",
       "      <td>0.075271</td>\n",
       "      <td>0.049104</td>\n",
       "      <td>0.036609</td>\n",
       "      <td>0.035557</td>\n",
       "      <td>0.045719</td>\n",
       "      <td>0.053202</td>\n",
       "      <td>0.038946</td>\n",
       "      <td>0.040760</td>\n",
       "      <td>0.060210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416766</th>\n",
       "      <td>If it is necessary to use colors , try to choo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.028905</td>\n",
       "      <td>0.028322</td>\n",
       "      <td>0.078900</td>\n",
       "      <td>0.031356</td>\n",
       "      <td>0.087621</td>\n",
       "      <td>0.058490</td>\n",
       "      <td>0.044907</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036505</td>\n",
       "      <td>0.050081</td>\n",
       "      <td>0.033357</td>\n",
       "      <td>0.024839</td>\n",
       "      <td>0.024067</td>\n",
       "      <td>0.048078</td>\n",
       "      <td>0.070205</td>\n",
       "      <td>0.077463</td>\n",
       "      <td>0.044667</td>\n",
       "      <td>0.040994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416767</th>\n",
       "      <td>Calgary Stampeders ,</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>0.037511</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416768 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label  \\\n",
       "0       There is manuscript evidence that Austen conti...      1   \n",
       "1       In a remarkable comparative analysis , Mandaea...      1   \n",
       "2       Before Persephone was released to Hermes , who...      1   \n",
       "3       Cogeneration plants are commonly found in dist...      1   \n",
       "4       Geneva -LRB- , ; , ; , ; ; -RRB- is the second...      1   \n",
       "...                                                   ...    ...   \n",
       "416763  A Duke Nukem 3D version has been sold for Xbox...      0   \n",
       "416764  However , it is becoming replaced as a method ...      0   \n",
       "416765  There are hand gestures in both Hindu and Budd...      0   \n",
       "416766  If it is necessary to use colors , try to choo...      0   \n",
       "416767                               Calgary Stampeders ,      0   \n",
       "\n",
       "        sentence_vectors_0  sentence_vectors_1  sentence_vectors_2  \\\n",
       "0                 0.032190            0.031540            0.068925   \n",
       "1                 0.037111            0.058199            0.079461   \n",
       "2                 0.033562            0.074113            0.073309   \n",
       "3                 0.028594            0.045670            0.061359   \n",
       "4                 0.036368            0.035617            0.077071   \n",
       "...                    ...                 ...                 ...   \n",
       "416763            0.041659            0.065333            0.089201   \n",
       "416764            0.037939            0.037286            0.092645   \n",
       "416765            0.042634            0.041708            0.090511   \n",
       "416766            0.028905            0.028322            0.078900   \n",
       "416767            0.069585            0.042923            0.093800   \n",
       "\n",
       "        sentence_vectors_3  sentence_vectors_4  sentence_vectors_5  \\\n",
       "0                 0.053862            0.059696            0.027254   \n",
       "1                 0.062095            0.046984            0.031420   \n",
       "2                 0.056195            0.048367            0.028458   \n",
       "3                 0.041469            0.038020            0.058981   \n",
       "4                 0.039370            0.045866            0.030845   \n",
       "...                    ...                 ...                 ...   \n",
       "416763            0.045192            0.052742            0.035271   \n",
       "416764            0.063482            0.048975            0.054446   \n",
       "416765            0.046131            0.053824            0.036085   \n",
       "416766            0.031356            0.087621            0.058490   \n",
       "416767            0.047522            0.055462            0.037089   \n",
       "\n",
       "        sentence_vectors_6  sentence_vectors_7  ...  sentence_vectors_10  \\\n",
       "0                 0.031068            0.027564  ...             0.040653   \n",
       "1                 0.057655            0.140964  ...             0.046868   \n",
       "2                 0.032436            0.028797  ...             0.042810   \n",
       "3                 0.028009            0.024975  ...             0.052748   \n",
       "4                 0.035132            0.031208  ...             0.088666   \n",
       "...                    ...                 ...  ...                  ...   \n",
       "416763            0.040207            0.060186  ...             0.052612   \n",
       "416764            0.059083            0.082415  ...             0.047916   \n",
       "416765            0.041194            0.063919  ...             0.053751   \n",
       "416766            0.044907            0.024751  ...             0.036505   \n",
       "416767            0.042280            0.037511  ...             0.055325   \n",
       "\n",
       "        sentence_vectors_11  sentence_vectors_12  sentence_vectors_13  \\\n",
       "0                  0.036830             0.056090             0.027662   \n",
       "1                  0.042460             0.042827             0.031890   \n",
       "2                  0.038881             0.039153             0.028891   \n",
       "3                  0.066521             0.034926             0.232206   \n",
       "4                  0.041521             0.041864             0.031300   \n",
       "...                     ...                  ...                  ...   \n",
       "416763             0.047665             0.048076             0.035799   \n",
       "416764             0.043409             0.043783             0.032602   \n",
       "416765             0.075271             0.049104             0.036609   \n",
       "416766             0.050081             0.033357             0.024839   \n",
       "416767             0.050122             0.050555             0.037645   \n",
       "\n",
       "        sentence_vectors_14  sentence_vectors_15  sentence_vectors_16  \\\n",
       "0                  0.026803             0.053542             0.059242   \n",
       "1                  0.030900             0.039889             0.046461   \n",
       "2                  0.028034             0.175085             0.041891   \n",
       "3                  0.024089             0.048113             0.035455   \n",
       "4                  0.030373             0.039017             0.152504   \n",
       "...                     ...                  ...                  ...   \n",
       "416763             0.034687             0.069292             0.052155   \n",
       "416764             0.031590             0.040780             0.073071   \n",
       "416765             0.035557             0.045719             0.053202   \n",
       "416766             0.024067             0.048078             0.070205   \n",
       "416767             0.036476             0.047087             0.054844   \n",
       "\n",
       "        sentence_vectors_17  sentence_vectors_18  sentence_vectors_19  \n",
       "0                  0.162035             0.030802             0.045653  \n",
       "1                  0.033942             0.035510             0.052631  \n",
       "2                  0.050654             0.032125             0.051821  \n",
       "3                  0.027248             0.027884             0.040745  \n",
       "4                  0.033276             0.034803             0.051296  \n",
       "...                     ...                  ...                  ...  \n",
       "416763             0.038103             0.039862             0.059082  \n",
       "416764             0.034700             0.036303             0.054106  \n",
       "416765             0.038946             0.040760             0.060210  \n",
       "416766             0.077463             0.044667             0.040994  \n",
       "416767             0.040067             0.041918             0.062128  \n",
       "\n",
       "[416768 rows x 22 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split up for loading issues. Utilizing great lakes did not speed up the processing power of gensim. Notebooks in\n",
    "#Great Lakes and Coursera kept failing.\n",
    "\n",
    "train_df_bi_tri_vectors_1 = pd.read_csv('train_df_bi_tri_vectors_1.csv')\n",
    "train_df_bi_tri_vectors_2 = pd.read_csv('train_df_bi_tri_vectors_2.csv')\n",
    "train_df_bi_tri_vectors_3 = pd.read_csv('train_df_bi_tri_vectors_3.csv')\n",
    "train_df_bi_tri_vectors_4 = pd.read_csv('train_df_bi_tri_vectors_4.csv')\n",
    "\n",
    "frames = [train_df_bi_tri_vectors_1[0:100000], train_df_bi_tri_vectors_2[100000:200000], train_df_bi_tri_vectors_3[200000:300000], train_df_bi_tri_vectors_4[300000:]]\n",
    "train_df_bi_tri_vectors = pd.concat(frames)\n",
    "train_df_bi_tri_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "friendly-pioneer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_df_bi_tri_vectors = pd.read_csv('train_df_bi_tri_vectors.csv')\\n\\ntrain_df_bi_tri_vectors\""
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_bi_tri_vectors = pd.read_csv('train_df_bi_tri_vectors.csv')\n",
    "\n",
    "train_df_bi_tri_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "helpful-syndrome",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bi_tri_lda_model_saved_model.get_document_topics(corpus, per_word_topics=False)[0]#[0][0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "solved-redhead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Bi_tri_lda_model_saved_model.get_document_topics(corpus, per_word_topics=True)[0]#[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "familiar-induction",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_bow_test = id2word.doc2bow(clean_words[50])\n",
    "#doc_lda_test = Bi_tri_lda_model_saved_model[doc_bow_test]\n",
    "#doc_lda_test[0][1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indian-middle",
   "metadata": {},
   "source": [
    "# Text vector for test df\n",
    "Test DF code not used because the accuracy was too low with the train df train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "professional-presentation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"topic_count = 20\\n\\nfor y in range(topic_count):\\n    test_df['sentence_vectors_'+str(y)] = .01\\n\\nfor x in tqdm(range(len(test_df))):\\n    doc_bow_test = id2word.doc2bow(clean_words[x])\\n    doc_lda_test = saved_model[doc_bow_test]        \\n    for y in range(topic_count):\\n        test_df['sentence_vectors_'+str(y)][x] = doc_lda_test[y][1]\\n        \\ntest_df.to_csv('test_df_vectors.csv', index = False)\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved to csv\n",
    "'''topic_count = 20\n",
    "\n",
    "for y in range(topic_count):\n",
    "    test_df['sentence_vectors_'+str(y)] = .01\n",
    "\n",
    "for x in tqdm(range(len(test_df))):\n",
    "    doc_bow_test = id2word.doc2bow(clean_words[x])\n",
    "    doc_lda_test = saved_model[doc_bow_test]        \n",
    "    for y in range(topic_count):\n",
    "        test_df['sentence_vectors_'+str(y)][x] = doc_lda_test[y][1]\n",
    "        \n",
    "test_df.to_csv('test_df_vectors.csv', index = False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "damaged-zambia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"test_df_vectors = pd.read_csv('test_df_bi_tri_vectors.csv')\\n\\ntest_df_vectors\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''test_df_vectors = pd.read_csv('test_df_bi_tri_vectors.csv')\n",
    "\n",
    "test_df_vectors'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-amino",
   "metadata": {},
   "source": [
    "# Text vector for test df bigrams trigrams\n",
    "Test DF code not used because the accuracy was too low with the train df train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "imperial-brooklyn",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"topic_count = 20\\n\\nfor y in range(topic_count):\\n    test_df['sentence_vectors_'+str(y)] = .01\\n\\nfor x in tqdm(range(len(test_df))):\\n    doc_bow_test = id2word.doc2bow(data_bigrams_trigrams[x])\\n    doc_lda_test = Bi_tri_lda_model_saved_model[doc_bow_test]        \\n    for y in range(topic_count):\\n        test_df['sentence_vectors_'+str(y)][x] = doc_lda_test[0][y][1] #added the zero\\n        \\ntest_df.to_csv('test_df_bigrams_trigrams_vectors.csv', index = False)\""
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# saved to csv\n",
    "'''topic_count = 20\n",
    "\n",
    "for y in range(topic_count):\n",
    "    test_df['sentence_vectors_'+str(y)] = .01\n",
    "\n",
    "for x in tqdm(range(len(test_df))):\n",
    "    doc_bow_test = id2word.doc2bow(data_bigrams_trigrams[x])\n",
    "    doc_lda_test = Bi_tri_lda_model_saved_model[doc_bow_test]        \n",
    "    for y in range(topic_count):\n",
    "        test_df['sentence_vectors_'+str(y)][x] = doc_lda_test[0][y][1] #added the zero\n",
    "        \n",
    "test_df.to_csv('test_df_bigrams_trigrams_vectors.csv', index = False)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "pretty-factory",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_vectors_0</th>\n",
       "      <th>sentence_vectors_1</th>\n",
       "      <th>sentence_vectors_2</th>\n",
       "      <th>sentence_vectors_3</th>\n",
       "      <th>sentence_vectors_4</th>\n",
       "      <th>sentence_vectors_5</th>\n",
       "      <th>sentence_vectors_6</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_vectors_10</th>\n",
       "      <th>sentence_vectors_11</th>\n",
       "      <th>sentence_vectors_12</th>\n",
       "      <th>sentence_vectors_13</th>\n",
       "      <th>sentence_vectors_14</th>\n",
       "      <th>sentence_vectors_15</th>\n",
       "      <th>sentence_vectors_16</th>\n",
       "      <th>sentence_vectors_17</th>\n",
       "      <th>sentence_vectors_18</th>\n",
       "      <th>sentence_vectors_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.069585</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.047522</td>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.037089</td>\n",
       "      <td>0.042280</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055325</td>\n",
       "      <td>0.050122</td>\n",
       "      <td>0.050555</td>\n",
       "      <td>0.037645</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>0.047087</td>\n",
       "      <td>0.054844</td>\n",
       "      <td>0.040067</td>\n",
       "      <td>0.041918</td>\n",
       "      <td>0.062128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119087</th>\n",
       "      <td>119087</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.096282</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.043027</td>\n",
       "      <td>0.063772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119088</th>\n",
       "      <td>119088</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.096282</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.043027</td>\n",
       "      <td>0.063772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119089</th>\n",
       "      <td>119089</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.096282</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.043027</td>\n",
       "      <td>0.063772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119090</th>\n",
       "      <td>119090</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.096282</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.043027</td>\n",
       "      <td>0.063772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119091</th>\n",
       "      <td>119091</td>\n",
       "      <td>#NAME?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.044966</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.096282</td>\n",
       "      <td>0.048780</td>\n",
       "      <td>0.056929</td>\n",
       "      <td>0.038070</td>\n",
       "      <td>0.043399</td>\n",
       "      <td>...</td>\n",
       "      <td>0.056789</td>\n",
       "      <td>0.051448</td>\n",
       "      <td>0.051893</td>\n",
       "      <td>0.038641</td>\n",
       "      <td>0.037441</td>\n",
       "      <td>0.048333</td>\n",
       "      <td>0.056296</td>\n",
       "      <td>0.041127</td>\n",
       "      <td>0.043027</td>\n",
       "      <td>0.063772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119092 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id original_text  label  sentence_vectors_0  sentence_vectors_1  \\\n",
       "0            0         -2011    NaN            0.069585            0.042923   \n",
       "1            1         -2011    NaN            0.069585            0.042923   \n",
       "2            2         -2000    NaN            0.069585            0.042923   \n",
       "3            3         -1997    NaN            0.069585            0.042923   \n",
       "4            4         1.636    NaN            0.069585            0.042923   \n",
       "...        ...           ...    ...                 ...                 ...   \n",
       "119087  119087        #NAME?    NaN            0.044966            0.044059   \n",
       "119088  119088        #NAME?    NaN            0.044966            0.044059   \n",
       "119089  119089        #NAME?    NaN            0.044966            0.044059   \n",
       "119090  119090        #NAME?    NaN            0.044966            0.044059   \n",
       "119091  119091        #NAME?    NaN            0.044966            0.044059   \n",
       "\n",
       "        sentence_vectors_2  sentence_vectors_3  sentence_vectors_4  \\\n",
       "0                 0.093800            0.047522            0.055462   \n",
       "1                 0.093800            0.047522            0.055462   \n",
       "2                 0.093800            0.047522            0.055462   \n",
       "3                 0.093800            0.047522            0.055462   \n",
       "4                 0.093800            0.047522            0.055462   \n",
       "...                    ...                 ...                 ...   \n",
       "119087            0.096282            0.048780            0.056929   \n",
       "119088            0.096282            0.048780            0.056929   \n",
       "119089            0.096282            0.048780            0.056929   \n",
       "119090            0.096282            0.048780            0.056929   \n",
       "119091            0.096282            0.048780            0.056929   \n",
       "\n",
       "        sentence_vectors_5  sentence_vectors_6  ...  sentence_vectors_10  \\\n",
       "0                 0.037089            0.042280  ...             0.055325   \n",
       "1                 0.037089            0.042280  ...             0.055325   \n",
       "2                 0.037089            0.042280  ...             0.055325   \n",
       "3                 0.037089            0.042280  ...             0.055325   \n",
       "4                 0.037089            0.042280  ...             0.055325   \n",
       "...                    ...                 ...  ...                  ...   \n",
       "119087            0.038070            0.043399  ...             0.056789   \n",
       "119088            0.038070            0.043399  ...             0.056789   \n",
       "119089            0.038070            0.043399  ...             0.056789   \n",
       "119090            0.038070            0.043399  ...             0.056789   \n",
       "119091            0.038070            0.043399  ...             0.056789   \n",
       "\n",
       "        sentence_vectors_11  sentence_vectors_12  sentence_vectors_13  \\\n",
       "0                  0.050122             0.050555             0.037645   \n",
       "1                  0.050122             0.050555             0.037645   \n",
       "2                  0.050122             0.050555             0.037645   \n",
       "3                  0.050122             0.050555             0.037645   \n",
       "4                  0.050122             0.050555             0.037645   \n",
       "...                     ...                  ...                  ...   \n",
       "119087             0.051448             0.051893             0.038641   \n",
       "119088             0.051448             0.051893             0.038641   \n",
       "119089             0.051448             0.051893             0.038641   \n",
       "119090             0.051448             0.051893             0.038641   \n",
       "119091             0.051448             0.051893             0.038641   \n",
       "\n",
       "        sentence_vectors_14  sentence_vectors_15  sentence_vectors_16  \\\n",
       "0                  0.036476             0.047087             0.054844   \n",
       "1                  0.036476             0.047087             0.054844   \n",
       "2                  0.036476             0.047087             0.054844   \n",
       "3                  0.036476             0.047087             0.054844   \n",
       "4                  0.036476             0.047087             0.054844   \n",
       "...                     ...                  ...                  ...   \n",
       "119087             0.037441             0.048333             0.056296   \n",
       "119088             0.037441             0.048333             0.056296   \n",
       "119089             0.037441             0.048333             0.056296   \n",
       "119090             0.037441             0.048333             0.056296   \n",
       "119091             0.037441             0.048333             0.056296   \n",
       "\n",
       "        sentence_vectors_17  sentence_vectors_18  sentence_vectors_19  \n",
       "0                  0.040067             0.041918             0.062128  \n",
       "1                  0.040067             0.041918             0.062128  \n",
       "2                  0.040067             0.041918             0.062128  \n",
       "3                  0.040067             0.041918             0.062128  \n",
       "4                  0.040067             0.041918             0.062128  \n",
       "...                     ...                  ...                  ...  \n",
       "119087             0.041127             0.043027             0.063772  \n",
       "119088             0.041127             0.043027             0.063772  \n",
       "119089             0.041127             0.043027             0.063772  \n",
       "119090             0.041127             0.043027             0.063772  \n",
       "119091             0.041127             0.043027             0.063772  \n",
       "\n",
       "[119092 rows x 23 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df_bigrams_trigrams_vectors = pd.read_csv('test_df_bigrams_trigrams_vectors.csv')\n",
    "\n",
    "test_df_bigrams_trigrams_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-poison",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "finished-locator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence_vectors_0</th>\n",
       "      <th>sentence_vectors_1</th>\n",
       "      <th>sentence_vectors_2</th>\n",
       "      <th>sentence_vectors_3</th>\n",
       "      <th>sentence_vectors_4</th>\n",
       "      <th>sentence_vectors_5</th>\n",
       "      <th>sentence_vectors_6</th>\n",
       "      <th>sentence_vectors_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sentence_vectors_10</th>\n",
       "      <th>sentence_vectors_11</th>\n",
       "      <th>sentence_vectors_12</th>\n",
       "      <th>sentence_vectors_13</th>\n",
       "      <th>sentence_vectors_14</th>\n",
       "      <th>sentence_vectors_15</th>\n",
       "      <th>sentence_vectors_16</th>\n",
       "      <th>sentence_vectors_17</th>\n",
       "      <th>sentence_vectors_18</th>\n",
       "      <th>sentence_vectors_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>180000</th>\n",
       "      <td>Berre-les-Alpes is a commune in the Alpes-Mari...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.090687</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.044778</td>\n",
       "      <td>0.052155</td>\n",
       "      <td>0.062617</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.059082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label  \\\n",
       "180000  Berre-les-Alpes is a commune in the Alpes-Mari...      1   \n",
       "\n",
       "        sentence_vectors_0  sentence_vectors_1  sentence_vectors_2  \\\n",
       "180000            0.090687            0.040819            0.089201   \n",
       "\n",
       "        sentence_vectors_3  sentence_vectors_4  sentence_vectors_5  \\\n",
       "180000            0.045192            0.052742            0.035271   \n",
       "\n",
       "        sentence_vectors_6  sentence_vectors_7  ...  sentence_vectors_10  \\\n",
       "180000            0.040207            0.035672  ...             0.052612   \n",
       "\n",
       "        sentence_vectors_11  sentence_vectors_12  sentence_vectors_13  \\\n",
       "180000             0.047665             0.048076             0.035799   \n",
       "\n",
       "        sentence_vectors_14  sentence_vectors_15  sentence_vectors_16  \\\n",
       "180000             0.034687             0.044778             0.052155   \n",
       "\n",
       "        sentence_vectors_17  sentence_vectors_18  sentence_vectors_19  \n",
       "180000             0.062617             0.039862             0.059082  \n",
       "\n",
       "[1 rows x 22 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_bi_tri_vectors.iloc[[180000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "genuine-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_vectors_0</th>\n",
       "      <th>sentence_vectors_1</th>\n",
       "      <th>sentence_vectors_2</th>\n",
       "      <th>sentence_vectors_3</th>\n",
       "      <th>sentence_vectors_4</th>\n",
       "      <th>sentence_vectors_5</th>\n",
       "      <th>sentence_vectors_6</th>\n",
       "      <th>sentence_vectors_7</th>\n",
       "      <th>sentence_vectors_8</th>\n",
       "      <th>sentence_vectors_9</th>\n",
       "      <th>sentence_vectors_10</th>\n",
       "      <th>sentence_vectors_11</th>\n",
       "      <th>sentence_vectors_12</th>\n",
       "      <th>sentence_vectors_13</th>\n",
       "      <th>sentence_vectors_14</th>\n",
       "      <th>sentence_vectors_15</th>\n",
       "      <th>sentence_vectors_16</th>\n",
       "      <th>sentence_vectors_17</th>\n",
       "      <th>sentence_vectors_18</th>\n",
       "      <th>sentence_vectors_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139689</th>\n",
       "      <td>0.039358</td>\n",
       "      <td>0.038447</td>\n",
       "      <td>0.084596</td>\n",
       "      <td>0.051665</td>\n",
       "      <td>0.073120</td>\n",
       "      <td>0.033227</td>\n",
       "      <td>0.037909</td>\n",
       "      <td>0.056721</td>\n",
       "      <td>0.069944</td>\n",
       "      <td>0.044219</td>\n",
       "      <td>0.049770</td>\n",
       "      <td>0.045073</td>\n",
       "      <td>0.045395</td>\n",
       "      <td>0.033777</td>\n",
       "      <td>0.052607</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.049309</td>\n",
       "      <td>0.035827</td>\n",
       "      <td>0.060830</td>\n",
       "      <td>0.055918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365169</th>\n",
       "      <td>0.061640</td>\n",
       "      <td>0.038022</td>\n",
       "      <td>0.083090</td>\n",
       "      <td>0.042097</td>\n",
       "      <td>0.049129</td>\n",
       "      <td>0.055689</td>\n",
       "      <td>0.037453</td>\n",
       "      <td>0.033228</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.043594</td>\n",
       "      <td>0.049008</td>\n",
       "      <td>0.067234</td>\n",
       "      <td>0.044783</td>\n",
       "      <td>0.033347</td>\n",
       "      <td>0.032311</td>\n",
       "      <td>0.087380</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>0.035493</td>\n",
       "      <td>0.037132</td>\n",
       "      <td>0.077870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166281</th>\n",
       "      <td>0.042802</td>\n",
       "      <td>0.041914</td>\n",
       "      <td>0.090515</td>\n",
       "      <td>0.046315</td>\n",
       "      <td>0.053939</td>\n",
       "      <td>0.036316</td>\n",
       "      <td>0.041501</td>\n",
       "      <td>0.036747</td>\n",
       "      <td>0.047202</td>\n",
       "      <td>0.073297</td>\n",
       "      <td>0.053843</td>\n",
       "      <td>0.048846</td>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.036851</td>\n",
       "      <td>0.035769</td>\n",
       "      <td>0.045903</td>\n",
       "      <td>0.078562</td>\n",
       "      <td>0.039167</td>\n",
       "      <td>0.040962</td>\n",
       "      <td>0.060303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38458</th>\n",
       "      <td>0.064590</td>\n",
       "      <td>0.039842</td>\n",
       "      <td>0.087067</td>\n",
       "      <td>0.044111</td>\n",
       "      <td>0.051480</td>\n",
       "      <td>0.034427</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>0.034819</td>\n",
       "      <td>0.068899</td>\n",
       "      <td>0.069607</td>\n",
       "      <td>0.051353</td>\n",
       "      <td>0.046524</td>\n",
       "      <td>0.046926</td>\n",
       "      <td>0.034942</td>\n",
       "      <td>0.033857</td>\n",
       "      <td>0.043707</td>\n",
       "      <td>0.050908</td>\n",
       "      <td>0.037191</td>\n",
       "      <td>0.038909</td>\n",
       "      <td>0.057669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317952</th>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.069706</td>\n",
       "      <td>0.077256</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>0.046074</td>\n",
       "      <td>0.046799</td>\n",
       "      <td>0.077126</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.044778</td>\n",
       "      <td>0.052155</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.039862</td>\n",
       "      <td>0.059082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93939</th>\n",
       "      <td>0.029405</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.062962</td>\n",
       "      <td>0.031899</td>\n",
       "      <td>0.071834</td>\n",
       "      <td>0.094108</td>\n",
       "      <td>0.028380</td>\n",
       "      <td>0.025179</td>\n",
       "      <td>0.084431</td>\n",
       "      <td>0.033033</td>\n",
       "      <td>0.054439</td>\n",
       "      <td>0.050947</td>\n",
       "      <td>0.051238</td>\n",
       "      <td>0.059875</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0.031607</td>\n",
       "      <td>0.071420</td>\n",
       "      <td>0.044198</td>\n",
       "      <td>0.062743</td>\n",
       "      <td>0.041703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131621</th>\n",
       "      <td>0.039712</td>\n",
       "      <td>0.062279</td>\n",
       "      <td>0.085032</td>\n",
       "      <td>0.066449</td>\n",
       "      <td>0.050277</td>\n",
       "      <td>0.033622</td>\n",
       "      <td>0.038328</td>\n",
       "      <td>0.034005</td>\n",
       "      <td>0.043921</td>\n",
       "      <td>0.044612</td>\n",
       "      <td>0.050153</td>\n",
       "      <td>0.045437</td>\n",
       "      <td>0.045829</td>\n",
       "      <td>0.034126</td>\n",
       "      <td>0.033066</td>\n",
       "      <td>0.066054</td>\n",
       "      <td>0.073086</td>\n",
       "      <td>0.036322</td>\n",
       "      <td>0.037999</td>\n",
       "      <td>0.079689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276246</th>\n",
       "      <td>0.034129</td>\n",
       "      <td>0.053524</td>\n",
       "      <td>0.093161</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.043209</td>\n",
       "      <td>0.028896</td>\n",
       "      <td>0.032940</td>\n",
       "      <td>0.029224</td>\n",
       "      <td>0.037746</td>\n",
       "      <td>0.058424</td>\n",
       "      <td>0.063186</td>\n",
       "      <td>0.039049</td>\n",
       "      <td>0.099636</td>\n",
       "      <td>0.029328</td>\n",
       "      <td>0.028418</td>\n",
       "      <td>0.056768</td>\n",
       "      <td>0.042728</td>\n",
       "      <td>0.031216</td>\n",
       "      <td>0.072824</td>\n",
       "      <td>0.068486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198410</th>\n",
       "      <td>0.040739</td>\n",
       "      <td>0.039895</td>\n",
       "      <td>0.086214</td>\n",
       "      <td>0.044089</td>\n",
       "      <td>0.051352</td>\n",
       "      <td>0.034561</td>\n",
       "      <td>0.039360</td>\n",
       "      <td>0.059293</td>\n",
       "      <td>0.044934</td>\n",
       "      <td>0.045668</td>\n",
       "      <td>0.099315</td>\n",
       "      <td>0.046499</td>\n",
       "      <td>0.046880</td>\n",
       "      <td>0.035070</td>\n",
       "      <td>0.034037</td>\n",
       "      <td>0.043696</td>\n",
       "      <td>0.050781</td>\n",
       "      <td>0.037278</td>\n",
       "      <td>0.038987</td>\n",
       "      <td>0.081351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310253</th>\n",
       "      <td>0.041659</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>0.035271</td>\n",
       "      <td>0.040207</td>\n",
       "      <td>0.035672</td>\n",
       "      <td>0.070588</td>\n",
       "      <td>0.046799</td>\n",
       "      <td>0.052612</td>\n",
       "      <td>0.047665</td>\n",
       "      <td>0.048076</td>\n",
       "      <td>0.035799</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>0.044778</td>\n",
       "      <td>0.052155</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.064376</td>\n",
       "      <td>0.083596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312576 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentence_vectors_0  sentence_vectors_1  sentence_vectors_2  \\\n",
       "139689            0.039358            0.038447            0.084596   \n",
       "365169            0.061640            0.038022            0.083090   \n",
       "166281            0.042802            0.041914            0.090515   \n",
       "38458             0.064590            0.039842            0.087067   \n",
       "317952            0.041659            0.040819            0.089201   \n",
       "...                    ...                 ...                 ...   \n",
       "93939             0.029405            0.028812            0.062962   \n",
       "131621            0.039712            0.062279            0.085032   \n",
       "276246            0.034129            0.053524            0.093161   \n",
       "198410            0.040739            0.039895            0.086214   \n",
       "310253            0.041659            0.040819            0.089201   \n",
       "\n",
       "        sentence_vectors_3  sentence_vectors_4  sentence_vectors_5  \\\n",
       "139689            0.051665            0.073120            0.033227   \n",
       "365169            0.042097            0.049129            0.055689   \n",
       "166281            0.046315            0.053939            0.036316   \n",
       "38458             0.044111            0.051480            0.034427   \n",
       "317952            0.069706            0.077256            0.035271   \n",
       "...                    ...                 ...                 ...   \n",
       "93939             0.031899            0.071834            0.094108   \n",
       "131621            0.066449            0.050277            0.033622   \n",
       "276246            0.057107            0.043209            0.028896   \n",
       "198410            0.044089            0.051352            0.034561   \n",
       "310253            0.045192            0.052742            0.035271   \n",
       "\n",
       "        sentence_vectors_6  sentence_vectors_7  sentence_vectors_8  \\\n",
       "139689            0.037909            0.056721            0.069944   \n",
       "365169            0.037453            0.033228            0.042918   \n",
       "166281            0.041501            0.036747            0.047202   \n",
       "38458             0.063173            0.034819            0.068899   \n",
       "317952            0.040207            0.035672            0.046074   \n",
       "...                    ...                 ...                 ...   \n",
       "93939             0.028380            0.025179            0.084431   \n",
       "131621            0.038328            0.034005            0.043921   \n",
       "276246            0.032940            0.029224            0.037746   \n",
       "198410            0.039360            0.059293            0.044934   \n",
       "310253            0.040207            0.035672            0.070588   \n",
       "\n",
       "        sentence_vectors_9  sentence_vectors_10  sentence_vectors_11  \\\n",
       "139689            0.044219             0.049770             0.045073   \n",
       "365169            0.043594             0.049008             0.067234   \n",
       "166281            0.073297             0.053843             0.048846   \n",
       "38458             0.069607             0.051353             0.046524   \n",
       "317952            0.046799             0.077126             0.047665   \n",
       "...                    ...                  ...                  ...   \n",
       "93939             0.033033             0.054439             0.050947   \n",
       "131621            0.044612             0.050153             0.045437   \n",
       "276246            0.058424             0.063186             0.039049   \n",
       "198410            0.045668             0.099315             0.046499   \n",
       "310253            0.046799             0.052612             0.047665   \n",
       "\n",
       "        sentence_vectors_12  sentence_vectors_13  sentence_vectors_14  \\\n",
       "139689             0.045395             0.033777             0.052607   \n",
       "365169             0.044783             0.033347             0.032311   \n",
       "166281             0.049245             0.036851             0.035769   \n",
       "38458              0.046926             0.034942             0.033857   \n",
       "317952             0.048076             0.035799             0.034687   \n",
       "...                     ...                  ...                  ...   \n",
       "93939              0.051238             0.059875             0.041787   \n",
       "131621             0.045829             0.034126             0.033066   \n",
       "276246             0.099636             0.029328             0.028418   \n",
       "198410             0.046880             0.035070             0.034037   \n",
       "310253             0.048076             0.035799             0.034687   \n",
       "\n",
       "        sentence_vectors_15  sentence_vectors_16  sentence_vectors_17  \\\n",
       "139689             0.042254             0.049309             0.035827   \n",
       "365169             0.087380             0.048583             0.035493   \n",
       "166281             0.045903             0.078562             0.039167   \n",
       "38458              0.043707             0.050908             0.037191   \n",
       "317952             0.044778             0.052155             0.038103   \n",
       "...                     ...                  ...                  ...   \n",
       "93939              0.031607             0.071420             0.044198   \n",
       "131621             0.066054             0.073086             0.036322   \n",
       "276246             0.056768             0.042728             0.031216   \n",
       "198410             0.043696             0.050781             0.037278   \n",
       "310253             0.044778             0.052155             0.038103   \n",
       "\n",
       "        sentence_vectors_18  sentence_vectors_19  \n",
       "139689             0.060830             0.055918  \n",
       "365169             0.037132             0.077870  \n",
       "166281             0.040962             0.060303  \n",
       "38458              0.038909             0.057669  \n",
       "317952             0.039862             0.059082  \n",
       "...                     ...                  ...  \n",
       "93939              0.062743             0.041703  \n",
       "131621             0.037999             0.079689  \n",
       "276246             0.072824             0.068486  \n",
       "198410             0.038987             0.081351  \n",
       "310253             0.064376             0.083596  \n",
       "\n",
       "[312576 rows x 20 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = train_df_bi_tri_vectors[['sentence_vectors_0',\n",
    "                    'sentence_vectors_1',\n",
    "                    'sentence_vectors_2',\n",
    "                    'sentence_vectors_3',\n",
    "                    'sentence_vectors_4',\n",
    "                    'sentence_vectors_5',\n",
    "                    'sentence_vectors_6',\n",
    "                    'sentence_vectors_7',\n",
    "                    'sentence_vectors_8',\n",
    "                    'sentence_vectors_9',\n",
    "                    'sentence_vectors_10',\n",
    "                    'sentence_vectors_11',\n",
    "                    'sentence_vectors_12',\n",
    "                    'sentence_vectors_13',\n",
    "                    'sentence_vectors_14',\n",
    "                    'sentence_vectors_15',\n",
    "                    'sentence_vectors_16',\n",
    "                    'sentence_vectors_17',\n",
    "                    'sentence_vectors_18',\n",
    "                    'sentence_vectors_19',]]\n",
    "y = train_df_bi_tri_vectors['label']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "thick-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5369434520728733\n",
      "0.4995641475916742\n",
      "0.33236362704327155\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "clf = LogisticRegression(solver='lbfgs', multi_class='auto')\n",
    "#clf.fit(X_train[0:10000], y_train[0:10000])\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#X_dev = vectorizer.transform(dev_df['bio'])\n",
    "#y_dev = list(dev_df.nationality)\n",
    "\n",
    "# dummy classifier for testing purposes\n",
    "dummy_clf_uniform = DummyClassifier(strategy=\"uniform\")\n",
    "dummy_clf_uniform.fit(X_train, y_train)\n",
    "\n",
    "dummy_clf_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_clf_frequent.fit(X_train, y_train)\n",
    "\n",
    "lr_tiny_preds = clf.predict(X_test)\n",
    "rand_preds = dummy_clf_uniform.predict(X_test)\n",
    "mf_preds = dummy_clf_frequent.predict(X_test)\n",
    "\n",
    "lr_f1 = f1_score(y_test, lr_tiny_preds, average='macro')\n",
    "rand_f1 = f1_score(y_test, rand_preds, average='macro')\n",
    "mf_f1 = f1_score(y_test, mf_preds, average='macro')\n",
    "\n",
    "print(lr_f1)\n",
    "print(rand_f1)\n",
    "print(mf_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "inside-functionality",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:Layer dense is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "9768/9768 [==============================] - 7s 681us/step - loss: 0.7047 - accuracy: 0.5253\n",
      "Epoch 2/10\n",
      "9768/9768 [==============================] - 6s 662us/step - loss: 0.6786 - accuracy: 0.5743\n",
      "Epoch 3/10\n",
      "9768/9768 [==============================] - 6s 662us/step - loss: 0.6728 - accuracy: 0.5813\n",
      "Epoch 4/10\n",
      "9768/9768 [==============================] - 7s 698us/step - loss: 0.6693 - accuracy: 0.5857\n",
      "Epoch 5/10\n",
      "9768/9768 [==============================] - 7s 729us/step - loss: 0.6674 - accuracy: 0.5888\n",
      "Epoch 6/10\n",
      "9768/9768 [==============================] - 7s 670us/step - loss: 0.6663 - accuracy: 0.5893\n",
      "Epoch 7/10\n",
      "9768/9768 [==============================] - 7s 685us/step - loss: 0.6650 - accuracy: 0.5915\n",
      "Epoch 8/10\n",
      "9768/9768 [==============================] - 7s 687us/step - loss: 0.6643 - accuracy: 0.5931\n",
      "Epoch 9/10\n",
      "9768/9768 [==============================] - 7s 692us/step - loss: 0.6638 - accuracy: 0.5950\n",
      "Epoch 10/10\n",
      "9768/9768 [==============================] - 7s 674us/step - loss: 0.6632 - accuracy: 0.5949\n",
      "3256/3256 - 2s - loss: 0.6624 - accuracy: 0.6023\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6623764038085938, 0.6023495197296143]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Dense(20, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.1),\n",
    "  tf.keras.layers.Dense(10),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping( monitor='val_loss', patience=30 )\n",
    "lr_reduction = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=.5, patience=10, verbose=1 )\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "model.evaluate(X_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
